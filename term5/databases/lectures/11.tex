\section{Оптимизация}

Итак, у нас есть диск с данными, есть менеджер буферов, есть обработчик запросов.
С другой стороны, есть парсер.
Осталось разорбать тот компонент, который для данного запроса построит отпимальный план исполнения.

Как только мы пропарсим, мы получим какой-то план, в лоб.
Наша задача "--- построить логический план, который эквивалентен исходному и оптимален.

Нам нужны свойства операций.
У нас все операции коммутативны.
Есть дистрибутивность:
\[ (R \cup S) \cup T = R \cup (S \cup T) \]
если имеет смысл, то
\[ (R \bowtie S) \bowtie T = R \bowtie (S \bowtie T) \]
Далее, есть ещё такая дистрибутивность:
\begin{gather*}
	\sigma_C (R \bowtie S) = \sigma_C(R) \bowtie \sigma_C(S) \\
	\sigma_{C_R} (R \bowtie S) = \sigma_{C_R}(R) \bowtie S \\
	\sigma_{C_R \land C_S} (R \bowtie S) = \sigma_{C_R}(R) \bowtie \sigma_{C_S}(S) \\
	\sigma_{C_1 \lor C_2} (R) = \sigma_{C_1} \cup \sigma_{C_2}
\end{gather*}
Очень часто предикаты проталкиваются вниз, поэтому не надо в запросах писать скобки вокруг соединений с предикатами внутри.
Наверх их тоже иногда поднимают.

Оптимизатор может делать ещё всякие весёлые вещи, заменяя бинарные операции на большей арности, например, дерево соединений заменить на одно, и пусть оптимизатор потом решает, в каком порядке их уже соединять.

Вообще, полезно оценивать стоимость операций.
Оно основывается на времени чтении отношений, индексов, сортировок, буферов конвееров.
От плана не меняется результат, а вот число чтений отношений и размеры промежуточных отношений зависят.
Промежуточные отношения имеют следующие свойства: они не хранятся персистентно, всегда можно сделать кластеризованным, всегда можно сортировать (если хочется), нет индексов.

Тут уже полезно перейти от количества операций чтения к размерам промежуточных отношений.
Понятно, что все факторы учесть невозможно, и нас не интересуют точные значения; нам только планы сравнивать.
Самое дорогое при выполнении "--- запись промежуточных записей, поэтому примерные размеры промежуточных данных нам вполне подходят.

Как же их считать? Ну... чёрная магия и эмпирические наблюдения.
Размеры результатов операций:
\begin{description}
\item[$\sigma_{\alpha = \$1}(R)$]
	Как мы знаем, размер результата равен
	\[ \frac{T(R)}{V(R, \alpha)} \]
	если значения распределены равномерно.
	В реальности, есть распределение Зипфа, которое говорит, что если упорядочить значения атрибута по колисеству записей, то эти числа образуют последовательность $1/n$.
\end{description}
