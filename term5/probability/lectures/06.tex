Обозначим $a_k = E |\xi|^k$. 
Через $a_k$ выражаются все моменты. Например, $D\xi = E(\xi - E\xi)^2 = a_2 - a_1^2$.

Поэтому, верно следующее утверждение:
\begin{assertion}
Если $\exists E |\xi|^n < +\infty$, то конечны все моменты порядка не больше чем $n$.
\end{assertion}
\begin{proof}
$E |\xi|^n = \int\limits_{-\infty}^{+\infty} |x|^n \d F(x)$, он сходится. 
Если уменьшим $n$, то получим интеграл, который будет мажорироваться исходным везде, кроме отрезка $[-1; 1]$, значит интеграл на $\R \setminus [-1; 1]$ сходится.
Ну а на этом отрезке он конечен: $|x| \leq 1, \d F = p \d x$, интеграл плотности конечен, а мы его умножаем на что-то, не большее единицы.
\end{proof}

Как мы уже выяснили, просто матожидания недостаточно для того, чтобы однозначно определить случайную величину. 
Вопрос: а достаточно ли такого множества значений $\{a_k\}_{k=1}^\infty$?
В общем случае ответ -- нет, но:

\begin{theorem}
    Если $\varlimsup \frac{(E|\xi|^n)^\frac1n}{n} < +\infty$, то моменты определяют распределение.
\end{theorem}

\begin{theorem}[Неравенство Йенсена]

Пусть $g(x)$ выпукла вниз, тогда $g(E \xi) \leq E g(\xi)$
\end{theorem}
\begin{proof}
    Через каждую точку графика $g$ можно провести прямую, которая ограничивает график снизу (это будет просто касательная) \TODO поясняющая картинка \TODO
    
    Возьмем точку $x_0 = E \xi$, через нее проходит прямая $ax + b$, ограничивающая график снизу: $ax + b \leq g(x), ax_0 + b = g(x_0)$.

    Тогда $$g(\xi) \geq g(E\xi) + a(\xi - E\xi)$$. 
    А теперь возьмем матожидание от обеих частей: 
    \begin{gather*}
    E(g(E\xi)) = g(E\xi) \text{как матожидание константы},\\
    E a(\xi - E\xi) = E a\xi - E aE\xi = E a\xi - E a\xi = 0
    \end{gather*}
    
    Откуда получаем $$g(E \xi) \leq E g(\xi)$$.
\end{proof}
\begin{conseq}[Неравенство Лягунова]
    $0 < s < t$. Тогда $$(E |\xi|^s)^\frac1s \leq (E |\xi|^t)^\frac1t$$.
\end{conseq}
\begin{proof}
    Применим Йенсена к $g(x) = |x|^\frac{t}{s}$
\end{proof}
\begin{conseq}
$|E\xi| \leq E|\xi|$.
\end{conseq}

\begin{theorem}[Неравенство Гёльдера]
    
$p > 1, q > 1, \frac1p + \frac1q = 1$, $E |\xi|^p, E|\eta|^q < \infty$. Тогда
$$E|\xi\eta| \leq (E |\xi|^p)^\frac1p (E |\eta|^q)^\frac1q$$
\end{theorem}
\begin{proof}
Если $\xi = 0$ или $\eta = 0$, то $0 \leq 0$. Иначе $E > 0$.

Заведем обозначения 
\begin{gather*}
\widetilde{\xi} = \frac{|\xi|}{(E |\xi|^p)^\frac1p}\\
\widetilde{\eta} = \frac{|\eta|}{(E |\eta|^q)^\frac1q}
\end{gather*}

Пусть $x, y, a, b > 0, a + b = 1$. Тогда верно $$x^ay^b \leq ax + by$$
Прологарифмируем это, получим $$a \ln x + b \ln y \leq \ln (ax + by)$$.

Можно нарисовать картиночку \TODO нарисовать \TODO, на которой левая часть это будет какая-то точка на отрезке, соединяющем точки $(x, \ln x)$ и $(y, \ln y)$, а правая часть -- точка на графике логарифма с той же координатой по $x$, поэтому неравенство выполнится.

Возьмем
\begin{gather*}
a = \frac1p, b = \frac1q\\
x = \widetilde{\xi}^p, y = \widetilde{\eta}^q
\end{gather*}

Подставляем в неравенство, берем матожидание
\begin{gather*}
E ax = E \frac1p \frac{|\xi|^p}{E|\xi|^p} = \frac1p \frac{1}{E|\xi|^p} E |\xi|^p = \frac 1p\\
E \widetilde{\xi} \widetilde{\eta} \leq \frac1p \cdot 1 + \frac1q \cdot 1 = 1\\
E |\xi||\eta| \leq (E |\xi|^p)^\frac1p (E |\eta|^q)^\frac1q
\end{gather*}

\end{proof}

Другие характеристики распределения:
\begin{enumerate}
\item Носитель -- множество, куда мы попадаем с вероятностью 1.
\item Определим $z_p = \sup \{x \mid F_\xi (x) \leq p\}$. Тогда $z_\frac12$ -- медиана, $z_\frac14, z_\frac34$ -- квартили.
\item Мода = $\arg\max p_\xi(x)$.
\end{enumerate}


\begin{Def}
    $E_{\vec{\xi}} = (E_{\xi_1}, \dots, E_{\xi_n})$.
\end{Def}
\begin{Def}
    Ковариацией пары случайных величин/векторов $\xi$ и $\eta$ называется $$cov(\xi, \eta) = E((\xi - E\xi)(\eta - E\eta) = E\xi\eta - E\xi E\eta$$ 
    В частости, при $\xi = \eta$ ковариация это дисперсия.
\end{Def}

\begin{theorem}[Свойства ковариации]
\begin{enumerate}
    \item $cov(\xi, \eta)$ -- билинейная по каждому аргументу, симметричная форма.
    \item Если $\xi, \eta$ независимы, то $cov(\xi, \eta) = 0$.
\end{enumerate}
\end{theorem}

Вот у нас есть $\xi = (\xi_1, \dots, \xi_n)$. Можем рассмотреть векторное пространство случайных векторов, $x_i$ образуют базис этого пространства.

\begin{Def}
    $\sigma_{ij} = cov(\xi_i, \xi_j)$

    $\sigma_{i,j=1}^n$ -- матрица ковариаций -- аналог дисперсии. Эта матрица симметрична и неотрицательно определена (вот в этом векторном пространстве).
\end{Def}
Доказательство неотрицательной определенности:
\begin{proof}
Напоминание: $A$ неотрицательно определена, если $xAx \geq 0$ для любого вектора $x$. 

Возьмем случайную величину $\xi$ из векторного пространства, она представляется в виде линейной комбинации $\xi_i$. Тогда

$$0 \leq D(\sum\limits_{i = 1}^n c_i \xi_i) = E(\sum c_i (\xi_i - E \xi_i)^2) = \sum\limits_{i,j=1}^n c_i c_j \sigma_{ij}$$
Что и требовалось.
\end{proof}

\begin{Def}
    Коэффициентом корреляции называют $\rho(\xi, \eta) = \frac{cov(\xi, \eta)}{\sqrt{D_\xi D_\eta}}$
    
    Если $\rho(\xi, \eta) = 0$, то $\xi, \eta$ называют некоррелироваными.
\end{Def}
\begin{Rem}
    $|\rho| \leq 1$: применим неравенство Гёльдера с $p=q=2$ к $\xi - E\xi$ и $\eta - E\eta$.
\end{Rem}

Любое распределение, симметричное относительно начала координат, дает нулевую корреляцию \TODO почему?

Задача линейного прогноза: пусть есть случайные величины $\xi, \eta$, мы знаем $\xi$, но не знаем $\eta$, хотим ее как-то угадать, линейно ее приблизив величиной $\xi$:
$\eta = g(\xi) = a\xi + b$.

Для этого мы будем минимизировать $E(\eta - g(\xi))^2$.  

Упражнение: если $E(\eta - a^*\xi -b^*)^2$ -- минимум, то $a^* = \frac{cov(\xi, \eta)}{D\xi}, b^* = E\eta - a^*E\xi$.

Можно заметить, что $E(\eta - a^*\xi -b^*)^2 = (1 - \rho)^2 D\eta$ (просто раскроем скобки). Тогда $\eta =  a\xi + b$ тогда и только тогда когда $|\rho| = 1$

\begin{Def}
Пространство $L^2$ случайных векторов -- пространство векторов с конечным моментом: $E \xi^2 < \infty$
\end{Def}
\begin{Rem}
Много где, где пишется ``вектор'', имеется в виду ``вектор''
\end{Rem}

\TODO видимо это пространство бесконечномерное получается, надо уточнить

Упражнение: в нем $cov(\xi, \eta)$ -- скалярное произведение

``Длина'' $\xi$ это $\sqrt{(\xi, \xi)} = \sqrt{D\xi} = \sigma \xi$ -- среднеквадратичное отклонение.

``Косинус угла'' это $\rho(\xi, \eta)$, некореллируемые величины -- перпендикулярные.

Лучшее линейное приближение $\eta$ -- проекция на плоскость $a\xi + b$ \TODO картинка, проясняющая это


\section{Общий (функциональный) прогноз}
   
Мы хотим приблизить $\eta$ борелевской функцией $g(\xi)$.

\begin{Def}
Пусть $\forall x\colon g(x) = E(\eta \mid \xi = x)$. Тогда $E(\eta \mid \xi) = g(\xi)$.
\end{Def}

\begin{Def}
    Пусть $\mathbb{A} \subset \mathbb{F}$ -- $\sigma$-алгебра.

    $\eta_\mathbb{A} = E(\eta \mid \mathbb{A})$ -- $\mathbb{A}$-измеримая случайная величина (то есть $\forall B \in \mathbb{B}\colon E(\eta \mid \mathbb{A})^{-1}(B) \in \mathbb{A}$),
    такая что $\forall A \in \mathbb{A}\colon E\eta \mathbb{1}_A = E_{\eta_\mathbb{A}} \mathbb{1}_A$
\end{Def}
\begin{exmp}
    Пусть $\Sigma = \R$, то случайная величина -- какая-то функция.
    \begin{enumerate}
    \item
        $\mathbb{A} = \{\varnothing, \R\}$, тогда $\eta_\mathbb{A} = E\eta$
    \item
        $\mathbb{A} = \sigma(\{[k, k + 1)\})$, тогда $\eta_\mathbb{A}$ -- объединение прямоугольников по площади таких же, как площадь под графиком \TODO wat?
    \item   
        $\mathbb{A} = \{A \colon A = -A\}$, $\eta_\mathbb{A}(w) = \frac{\eta(w) + \eta(-w)}{2}$
    \end{enumerate}
\end{exmp}

\begin{Def}
    $\Xi$ -- набор множеств, тогда $E(\eta \mid \Xi) = E(\eta \mid \sigma(\Xi))$

    $\xi$ -- случайная величина, тогда $E(\eta \mid \xi) = E(\eta \mid \mathbb{F}_\xi)$
\end{Def}
\begin{Rem}
    Два определения равносильны, доказывать не будем.
\end{Rem}