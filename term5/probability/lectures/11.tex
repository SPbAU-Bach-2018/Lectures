\chapter{Случайные процессы}
\begin{Def}
$T$ -- ``время'', $\Omega$ -- исходы.

$\xi(t, w) = \xi_t(w) \colon T \times \Omega \to \R$ такая, что $\forall t \in T\colon \xi_t \colon \Omega \to \R$ являтся случайной величиной.

Тогда $\xi$ -- случайный процесс.

По $T$:
\begin{enumerate}
\item $T$ -- конечно, тогда это -- случайные векторы.
\item $T$ -- счетно, тогда это процесс с дискретным времем.
\item $T = \R^n, [a, b]$ и т.п., тогда это процесс с непрерывным временем.
\end{enumerate}

По значениям: 
\begin{enumerate}
\item процессы с дискретным набором состояний (существует не более чем счетное $B \colon P(\xi_t \in B) = 1 \forall t \in T$) 
\item процессы с непрерывным множеством состояний.
\end{enumerate}

$\xi (\cdot, w)$ как функция $T \to \R$ называется реализацией (траекторией). 
\end{Def}
\begin{exmp}
Например, температура на улице -- случайный процесс. 
Но если мы посмотрим температуру в прошлом, то это будет ее траектория, так как она уже не случайная.
\end{exmp}

\begin{Def}
Пусть $t_1 < t_2 < \dots < t_n$. $(\xi_{t_1}, \dots, \xi_{t_n})$ -- случайный вектор, у него есть какое-то распределение.

Тогда  $P_\xi = \{ P_{(\xi_{t_1}, \dots, \xi_{t_n})}, n \in \N, (t_1, \dots, t_n) \in T^n \}$ -- семейство конечномерных распределений.
\end{Def}
\begin{exmp}
Могут быть процесы, которые имеют одинаковые семейства конечномерных распределений, но сами по себе будут разными, например, их траектории будут сильно различаться.

$T = [0, 1]$, $\Theta \sim U[0, 1]$, $\xi_t = 0, \eta_t = \mathbb{1}_{(\Theta(\omega) = t)}$

Семейства для $\xi_t$ и $\eta_t$ совпадают (для любого конечного набора $T$ вероятность того, что попадем в этот конечный набор, равна нулю), 
но траектории различаются: супремум значений у $\xi$ равен нулю, у $\eta$ равен единице.
\end{exmp}

\begin{Def}
Пишут $\xi_t \xrightarrow[]{d} \eta_t$, если их семейства распределений равны.

А когда выполняется $\forall t P(\xi_t = \eta_t) = 1$ (это несколько более сильное утверждение), то говорят, что $\xi$ и $\eta$ являются ``модификациями'' друг друга.
\end{Def}


Есть аналог теоремы (Колмогорова?), который говорит, что если есть семейство согласованных конечномерных распределений (если выкидываем $t_1$, то все равно получаем вектор из множества), 
то тогда можно построить процесс по этому семейству. \TODO

Множества $T$ могут быть самыми разными и совершненно не обязательно соответствовать типичному пониманию времени:
\begin{exmp}
Высота волны. $t$ -- время, $\omega$ -- случайные координаты. А можно и наоборот: $t$ -- координата, $\omega$ -- время.
\end{exmp}
\begin{exmp}
Аквариум. Набор моментов времени $T$ -- набор всех возможных Борелевских подмножеств аквариума: $T = \mathbb{B}$, $\omega$ -- момент времени, $\xi_t(\omega) =$ число рыбок в $t$ в момент времени $\omega$
\end{exmp}
\begin{exmp}
$T = \{\xi \colon \Omega\to \R\}$, $\xi$ -- случайные величины. $\eta_t(\omega) = t(\omega)$. Это тоже случайный процесс.
\end{exmp}
\begin{exmp}
$\xi(t, \omega) = A(\omega) \cos (\nu(\omega) t + \phi(\omega))$ -- колебательное движение, $A, \nu, \phi$ -- случайные величины. Получили опять случайный процесс.
\end{exmp}
\begin{exmp}
Пример из матстатистики: $X_1, \dots, X_n$ -- независимые случайные величины с функцией распределения $F(t)$. 

$F_n(t) = \frac1n \sum\limits_{k=1}^n \mathbb{1}_{(X_k(\omega) < t)}$ -- выборочная функция распределения.

$EF_n(t) = \frac1n \sum\limits_1^n P(X_k < t) = F(t)$

$DF_n(t) = \frac{1}{n^2} \sum F(t)(1 - F(t)) = \frac{F (1 - F)}{n} \to 0$

Из всего этого следует, что $F_n(t) \to F(t)$

$E\xi = \int x \d F(x)$, выборочное среднее $\int x \d F_n(x) = \frac1n \sum\limits_1^n X_k$

\TODO добавить в пример побольше текста и смысла \TODO

\end{exmp}

Типы случайных процессов:
\begin{enumerate}
\item С независимыми значениями: $\forall t_1, t_2, \dots \colon \xi_{t_1}, \xi_{t_2}, \dots$ -- независимы.

\item С независимыми приращениями: $\forall t_0 < t_1 < \dots \colon \xi_{t_0}, \xi_{t_1 - t_0}, \xi_{t_2 - t_1}, \dots$ -- независимы.
Например, $\eta_k$ -- независимы, $\xi_n = \eta_1 + \dots + \eta_n$.

\item Марковские процессы -- процессы, у которых выполняется Марковское свойство: 
$\forall t_1 < t_2 < \dots < t_n, \forall B \in \mathbb{B}, \forall x_1, \dots, x_{n-1} \in \R \colon P(\xi_{t_n} \in B \mid \xi_{t_1} = x_1, \dots, \xi_{t_{n-1}} = x_{n-1}) = P(\xi_{t_n} \in B \mid \xi_{t_{n-1}} = x_{n-1})$
На словах: не важно, какая была история у процесса, важно лишь последнее состояние.
\begin{exmp}
Температура, например, не является Марковским процессом: как правило, она каким-либо образом зависит от тренда, от того, как она менялась в последние дни.
\end{exmp}                                                                                                                                                                                 
\begin{exmp}
А подбрасывание монетки -- является
\end{exmp}
\item Процессы второго порядка: $\exists E \xi_t = a(t)$ -- среднее, $K(t, s) = cov(\xi_t, \xi_s)$ -- ковариационная функия, $R(t, s) = \frac{K(t, s)}{\sqrt{K(t, t)K(s, s)}}$ --корелляционная функция.

\item Гауссовские процессы: если все конечномерные распределения нормальные.

\item Стационарные процессы. 

В узком смысле: $\forall h \in T\colon P_{\xi_{t_1}, \dots, \xi_{t_n}} = P_{\xi_{t_1 + h}, \dots, \xi_{t_n + h}}$.

В широком смысле: $a(t) = a = const, K(t, s) = g(|t - s|)$

\item $t_1 < t_2$, $E(\xi_{t_2} \mid \xi_{t_1} = x) = x$ -- мартингал. Если $\geq x$, то субмартингал, если $\leq x$, то супермартингал.
\begin{exmp}
Например, бросание монетки -- мартингал, если выпало на $x$ орлов больше, чем решек, то в будущем в среднем так и будет.
\end{exmp}

\end{enumerate}

\begin{Def}
Пуассоновский поток -- случайный процесс со следующими свойствами:
\begin{enumerate}
\item $\pi_0 = 0$
\item С независимыми приращениями
\item Однородность по времени: $P(\pi_t - \pi_s = k) = P(\pi_{t-s} = k)$
\item $\pi_t \in \Z_+$
\end{enumerate}
\end{Def}
\TODO ступенчатая картинка \TODO

Пусть $G(t) = P(\pi_t = 0)$. Тогда $G(t + s) = P(\pi_s = 0) P(\pi_{t + s} = 0 \mid \pi_s = 0) = З(\pi_s = 0) P(\pi_{t + s} - \pi_s = 0) = G(s) G(t)$.
Тогда $G(t) = e^{-\lambda t}$, и интервалы между скачками независимы и распределены показательно, а отсюда $\pi_t \sim Poiss(\lambda t)$.

Таким образом, эти свойства определяют вид нашего процесса

\begin{Rem}
Очень популярный процесс, например, в теории массового обслуживания: обработка всяких запросов, очереди, и все такое прекрасно им описываются.
\end{Rem}

Можно сделать $\labmda$ переменной от $t$, тогда \TODO \TODO
