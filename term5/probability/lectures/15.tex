\TODO еще пара процессов случайного блуждания (ничего важного вроде) \TODO

\section{Марковские цепи с непрерывным временем}
У нас по-прежнему есть матрица перехода, только она теперь не от шагов зависит, а от времени: $P_{ij}(t), t \in [0, +\infty)$.

Свойства матрицы перехода:
\begin{enumerate}
\item $\sum\limits_j P_{ij}(t) = 1$
\item $P(t+s) = P(t)P(s)$ -- формула полной вероятности, уравнение Чэмпена-Колмогорова
\item Дополнительное соглашение (ниоткуда не выводится, но принимают за истину): $P_{ij}(t) \xlongrightarrow[t \to +0]{} \mathbb{1}_{i=j}$
\end{enumerate}
 
\begin{theorem}
$P_{ij}(t)$ равномерно непрерывно на $[0, +\infty)$
\end{theorem}
\begin{proof}
\begin{gather*}
P_{ij}(t+h) = P_{ii}(h) P_{ij}(t) + \sum\limits_{k \neq i} P_{ik}(h) P_{kj}(t) \\
1 - P_{ii}(h) = \sum\limits_{k \neq i} P_{ik}(h) \geq P_{ij}(t+h) - P_{ij}(t) = P_{ij}(t)(P_{ii}(h) - 1) + \sum\limits_{k \neq i} \dots \geq \\
\geq P_{ii}(h) - 1 \Ra |P_{ij}(t+h) - P_{ij}(t)| \leq 1 - P_{ii}(h) \to 0
\end{gather*}
\end{proof}

\begin{theorem}
Существуют производные в нуле: 
\begin{gather*}
a_{jj} = \lim\limits_{h \to +0} \frac{P_{jj}(h) - 1}{h} \in (-\infty, 0] \\
a_{ij} = \lim\limits_{h \to +0} \frac{P_{ij}(h)}{h} \in [0, +\infty)
\end{gather*}
\end{theorem}
\begin{proof}
Без доказательства.
\end{proof}

\subsection{Случай конечного числа состояний}

\begin{Def}
$A = (a_{ij})_{i,j=0}^N$ -- инфинитезимальная матрица (генератор процесса), если $\sum\limits_{j=0}^N a_{ij} = 0$ (консервативный процесс)
\end{Def}

$A = \lim\limits_{h \to +0} \frac{P(h) - E}{h} = P'(0)$

$P'(t) = \frac{P(t+h) - P(t)}{h} = P(t) \frac{P(h) - E}{h} \xlongrightarrow[h \to +0]{} P(t) A$ -- прямые ДУ Колмогорова.

Или же, можно вынести $P(t)$ с другой стороны, тогда получится $AP(t)$ -- обратные ДУ Колмогорова.

Если состояний конечное число, то не очень важно, какие уравнения брать, результат будет одинаковым: 
$$P(t) = e^{At} = \sum\limits_{k = 0}^\infty \frac{A^k}{k!}$$

Таким образом, $A$ и начальное распределение $\xi_0$ задают Марковскую цепь: $P(\xi_t = j) = \sum\limits_{k=0}^N P(\xi_0 = k) P_{kj}(t)$

\subsection{Бесконечное число состояний}
В случае консервативного процесса справедливы обратные ДУ Колмогорова (а прямые нет).

Если процесс не консервативен, то ни те ни другие неверны.

\begin{exmp}
Опять численность популяции: $\xi_t$ -- численность в момент времени $t$. $P_{j,j+1}(h) = \lambda_jh + o(h)$.

$A = \begin{matrix}
-\lambda_0 & \lambda_0 & 0 & 0 & \dots \\
\mu_1 & (-\mu_1 - \lambda_1) & \lambda_1 & 0 & \dots \\
0 & \mu_2 & (-\mu_2 - -\lambda_2) & 0 & \dots \\
\dots
\end{matrix}$

Если $\lambda_n = \lambda n, \mu_n = \mu n$ -- линейный рост.

Если $\lambda_n = \lambda n + a$ -- иммиграция.
\end{exmp}


\chapter{Элементы теории информации}
Классическая схема: есть $n$ равновероятных исходов с $P(\{w\}) = \frac1n$.
В этом случае, допустим, мы придумали меру неопределенности нашего эксперимента, или, количество информации, которую дает нам эксперимент.
Логично предположить, что если делаем какие-то действия (вытащили карту, потом бросили карту), то полученная информация складывается.
А количество исходов перемножается.

Поэтому, если есть информация $I = f(n)$, то $f(nm) = f(n) + f(m)$, где $n, m$ -- количество исходов.

Отсюда, $f$ -- логарифм. Если основание 2, то меряем инфу в битах, 3 -- тритах, 10 -- диты, если натуральный логарифм, то наты.
По умолчанию будем считать, что $f(n) = \log_2(n) = \sum \frac1n \log n = -\sum \frac1n \log \frac1n$ 

Вероятности могут быть разными, вводят следующее определение:
\begin{Def}
$\alpha$ -- некий эксперимент, $\xi$ -- случайная величина с рядом $p_k$, тогда $H(\alpha) = H(\xi) = \sum\limits_{k=1}^n -p_k \log p_k$.

$H$ называют либо количеством информации, либо степенью неопределенности, или же энтропией.
Это, по смыслу, средняя информация, которую мы получаем в результате эксперимента.
\end{Def}

\begin{theorem}
$H(p_1, \dots, p_n) \leq \log n$
\end{theorem}
\begin{proof}
$g = p \log p$ выпукла вверх, тогда $\frac1n \sum g(p_k) \leq g(\frac1n \sum p_k)$

$H = \sum g(p_k) \leq n \cdot -(\frac1n \sum p_k) \log \frac1n = \log n$
\end{proof}

\begin{theorem}
Пусть $M(p_1, \dots, p_n)$ -- функция со следующими свойствами:
\begin{enumerate}
\item Инвариантна относительно перестановки аргументов
\item $M(p, 1 -p ) \geq 0$ и ограничена на $[0, 1]$
\item $M(p_1, \dots, p_n) = M(p_1 + p_2, p_3, \dots, p_n) + (p_1 + p_2) M(\frac{p_1}{p_1 + p_2}, \frac{p_2}{p_1 + p_2})$.

Тогда $M = cH, c > 0$.
\end{enumerate}
\end{theorem}

Пусть провели два эксперимента: сначала $\alpha$, потом $\beta$. 
Посчитаем в таком случае энтропию.

\begin{gather*} 
H(\alpha \circ \beta) = -\sum\limits_i \sum\limits_k P(A_i B_k) \log  P(A_i B_k) = \\
= \sum\limits_i -P(A_i) \log P(A_i)\underbrace{\sum\limits_k P(B_k \mid A_i)}_{=1} + \underbrace{P(A_i)(\sum\limits_k -P(B_k \mid A_i) \log P(B_k \mid A_i)}_{=H(\beta \mid A_i} = \\
= H(\alpha) + \sum\limits_i P(A_i)H(\beta \mid A_i) = H(\alpha) + H(\beta \mid \alpha) =  \\
= H(\beta) + H(\alpha \mid \beta)
\end{gather*}

Эта формула называется формулой полной энтропии