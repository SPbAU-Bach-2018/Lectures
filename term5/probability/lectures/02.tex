\section{Условная вероятность}
\begin{Def}
    $P(A | B) = P_B(A) = \frac{P(A \cap B)}{P(B)}$ -- условная вероятность, вероятность события $A$ при условии события $B$.
\end{Def}

\begin{theorem}
    $P_B(A)$ -- вероятность (то есть, выполнены обе аксиомы)
\end{theorem}
\begin{proof}
\begin{enumerate}
\item
    Рассмотрим произвольные несовместные события $A_i$, проверим аддитивность:

    $P_B(\cup A_i) \equivDef \frac{P(B \cap \bigcup A_i)}{P(B)} = \frac{\cup BA_i}{P(B)} = \frac{\sum P(BA_i)}{P(B)} = \sum P_B(A_i)$
\item
    Нормировка: $P_B(\Omega) = \frac{P(B\Omega)}{P(B)} = 1$
\end{enumerate}
\end{proof}

\begin{Def}
    $A, B$ два события. Если $P(AB) = P(A)P(B)$, то они называются независимыми.
\end{Def}
\begin{Def}[Независимость в совокупности]

    Множество событий $\{A_i\}$ называется независимым, если для любого конечного его подмножества $\{A_{i_j} \} (j \in [1; k])$ выполняется:

    $$P(\bigcap\limits_{j=1}^k A_{i_j}) = \prod\limits_{j=1}^k P(A_{i_j})$$
\end{Def}
\begin{Rem}
Это определение является более сильным, чем просто попарная независимость любых двух событий из множества.
\end{Rem}
\begin{exmp}
Рассмотрим тетраэдр, покрасим три его стороны соответственно в красный, синий и зеленый цвета, а последнюю покрасим во все цвета сразу.
Тогда вероятность того, что сторона покрашена и в красный и в синий равна $P(RB) = \frac14 = P(R)P(B)$, поэтому события ``сторона красная'' и ``сторона синяя'' независимы.
Но события ``сторона красная'', ``сторона синяя'' и ``сторона зеленая'' не являются независимыми, так как $P(RBG) = \frac14 \neq P(R)P(B)P(G) = \frac18$. 
Тем не менее, они являются попарно независимыми.
\end{exmp}
\begin{Rem}
По умолчанию, когда говорится про независимость множества событий, имеется в виду сильная независимость.
\end{Rem}

Формула полной вероятности: пусть $\{H_k\}$ -- конечное или счетное разбиение $\Omega$. Тогда
$$ P(A) = P(A\Omega) = P(A \cap \bigcup\limits_k H_k) = P(\bigcup AH_k) = \sum\limits_k P(AH_k) = \sum\limits_k P(H_k) P(A | H_k)$$


Формула Байеса: 
$$ P(H_k | A) = \frac{P(H_k A)}{P(A)} = \frac{P(H_k A)}{\sum\limits_i P(H_i) P(A | H_i)} = \frac{P(H_k) P(A | H_k)}{\sum\limits_i P(H_i) P(A | H_i)}$$

\begin{lemma}[Бореля, Кантелли]
Есть бесконечное счетное множество событий $\{A_k\}_{k=1}^{\infty}$.
Событие $A$ "--- <<при исходе выполнилось бесконечно много событий среди $A_k$>>. Тогда:
\begin{enumerate}
    \item $\sum P(A_k) < \infty \Ra P(A) = 0$
    \item $\sum P(A_k) = \infty$ и $A_k$ независимы $\Ra P(A) = 1$
\end{enumerate}    
\end{lemma}
\begin{proof}
	Построим событие $A$ явно: исход $w \in A$ тогда и только тогда,
	когда он лежит в бесконечном количестве $A_k$ (то есть начиная с любого места в некотором $A_k$ встретится $w$):
    \[ A = \varlimsup A_k \coloneq \bigcap\limits_{n=1}^{\infty} \underbrace{\bigcup\limits_{k=n}^{\infty} A_k}_{B_n} \]
    Тут $B_n$ "--- это те исходы, которые встречаются в каком-нибудь $A_{k}$ при $k \ge n$.

    Заметим, что $B_n \searrow$ по включению: каждая точка либо есть в конечном числе $A_k$, тогда с какого-то момента ее в $B_n$ не будет (а до этого "--- будет), либо точка есть в бесконечном числе $A_k$ и тогда она есть во всех $B_n$.

    Теперь доказываем пункты леммы:
    \begin{enumerate}
	\item
    	Так как $B_n$ есть объединение $A_k$ с некоторого места, то:
    	\[ P(B_n) \leq \sum\limits_{k=n}^{\infty} P(A_k) \]
    	А часть справа стремится к нулю, так как является хвостом сходящегося ряда из условия.

		При этом $P(A) = P\left(\lim\limits_{n \to \infty} B_n\right) = \lim\limits_{n \to \infty} P(B_n)$ (последнее равенство по непрерывности вероятности).
		То есть $P(A) = 0$, что и требовалось. 

    \item
    Перейдем к дополнениям: $\bar A = \bigcup\limits_{n=1}^{\infty} \bigcap\limits_{k=n}^{\infty} \bar A_k$

    $P(\bigcup\limits_n^N \bar A_k) = \prod\limits_n^N P(\bar A_k)$, так как пересечение конечное, события независимы.
    Устремим $N$ к бесконечности, получим:

    \begin{gather*} 
    P(\bigcup\limits_n^{\infty}) = \prod\limits_n^{\infty} P(\bar A_k)\\
    \ln P(\bigcup\limits_n^{\infty} \bar A_k) = \sum\limits_n^{\infty} \ln(1 - P(A_k)) < 
    \end{gather*}     
    Заметим, что $\ln(1 - x) < -x$ при $x \in (0; 1)$, тогда
    \begin{gather*} 
     < -\sum\limits_n^{\infty} P(A_k) = -\infty \Ra P(\bigcap\limits_n^{\infty} \bar A_k) = 0 \\
    P(A) = 1 - P(\bar A) = 1 - P(\bigcup\limits_{n=1}^{\infty} \bigcap\limits_{k=n}^{\infty} \bar A_k) \geq 1 - \sum\limits_{n=1}^{\infty} P(\bigcap\limits_{k=n}^{\infty} \bar A_k) = 1 - 0 = 1
    \end{gather*} 
                                                                                     
    \end{enumerate}
\end{proof}

\section{Последовательность независимых событий}

Пусть у нас есть последовательность $(\Omega_n, \mathcal{F}_n, P_n)$ -- последовательность независимых экспериментов.
Хотим взять и построить вероятностное пространство для этой последовательности.

Понятно, что $\Omega = \bigtimes\limits_n \Omega_n$.
В качестве события $A$ можно рассматривать $A = A_1 \times A_2 \times A_3 \dots$. 
Не хотим возиться с бесконечными произведениями, хотим работать только с конечными, так гораздо проще. 
Тогда рассмотрим следующее произведение: $A = A_1 \times A_2 \times \dots \times A_n \times \Omega_{n+1} \times \Omega_{n+2} \times \dots$.
Оно означает, что с какого-то момента мы считаем все события достоверными и нам не важно, что конкретно там просходило. 

\begin{Def}
Такое $A$ называется цилиндром. $A_1 \times \dots \times A_n$ -- его $n$-мерное основание.
\end{Def}
\begin{Rem}
Почему цилиндр? Цилиндр это когда мы берем фигуру меньшей размерности, начинаем ее двигать  в пространстве, очерчивая некоторую фигуру. 
Так и здесь: есть основание, по остальным координатам условий нет, берем и просто двигаем вдоль них основание.
\end{Rem}

Цилиндры не образуют $\sigma$-алгебру, поэтому нельзя сказать, что $\mathcal{F}$ состоит из цилиндров.
Пересечение цилиндров это, конечно, цилиндр, а объединение -- не факт. Но можно сказать, что $\mathcal{F} = \sigma(\mathcal{E})$, где $\mathcal{E}$ -- набор всех цилиндров.

Для цилиндра $A$ логично определить $P(A) = \prod\limits_{k=1}^n P_k(A_k)$. 
Для остальных событий есть следующая теорема.
\begin{Def}
$\mathcal{E}$ называется полукольцом множеств, если это множество, замкнутое относительно операции пересечения, при этом, 
для любых его двух элементов $A, B$ должно выполняться $A \setminus B = \bigcup\limits_{j=1}^m C_j, C_j \in \mathcal{E}$
\end{Def}
\begin{theorem}[Каратеодори]
Пусть множество наборов $\mathcal{E}$ -- полукольцо, и на нем задана $\sigma$-аддитивная функция $P$ (то есть удовлетворяет аксиомам $1^*, 2$).

Тогда существует единственное ее $\sigma$-аддитивное продолжение на $\sigma(\mathcal{E})$.
\end{theorem}
\begin{proof}
Без доказательства.
\end{proof}
Согласно этой теореме, вероятность, определенную на цилиндрах,  можно единственным образом продолжить на все $\mathcal{F}$.
\begin{Rem}
Аналогия с линейной алгеброй: достаточно задать линейное отображение на базисе, на остальное пространство продолжается однозначно.
\end{Rem} 

\begin{exmp}
Задача о встречах. Два человека обговорили часовой интервал, в течение которого они хотят встретиться. 
Они приходят независимо друг от друга в какой-то случайный момент времени, каждый ждет 20 минут и потом уходит.
Надо посчитать вероятность встречи.

$\Omega_k = [0; 1], k = 1..2, \mathcal{F}$ -- все измеримые подмножества отрезка. Вероятность попасть -- длина.

Смотрим на прямое произведение двух отрезков, это квадрат.
Пусть точка $(x, y)$ -- моменты времени, когда пришли первый и второй человек. 
Тогда они встретились, если $|x - y| \leq \frac13$. 

Нарисуем множество точек, которые нам дают встречу \TODO картинка? \TODO

Хотим посчитать вероятность встречи. Воспользуемся теоремой. Для цилиндра (то есть прямоугольника) знаем вероятность попасть = произведение длин сторон = площадь.
Берем $\sigma$-оболочку прямоугольников, получаем все измеримые множества (доказывали на матане), доопределим вероятность на них, скажем, что она тоже будет равна площади. 
Тогда есть функция, которая на прямоугольниках совпадает с площадью. 
По теореме есть только одно ее продолжение на $\sigma$-оболочку, а мы только что нашли хотя бы одно.

Значит, для того, чтобы посчитать вероятность встречи, достаточно лишь посчитать площадь заштрихованной фигуры.
\end{exmp}

\begin{Rem}
В дальнейшем, конечно, проговоренный формализм будет так или иначе опускаться.
\end{Rem}

\begin{exmp}
Теперь экспериментов будет бесконечно, но они будут простыми: каждый раз берем и бросаем монетку, вероятности орла и решки (0 и 1) равны $\frac12$.

$\Omega = \{0, 1\}^{\N} \leftrightarrow [0, 1]$.
Цилиндры -- последовательности с фиксированным началом: если первое число 0, то это отрезок $[0; 0.5]$, иначе $[0.5; 1]$.
Если мы знаем два числа, то получаем отрезок длины $0.25$ и так далее.

Для всех цилиндров их длина совпадает с их вероятностью, тогда вероятность любого события = длина на $[0; 1]$.
\end{exmp}

\section{Схема Бернулли}

\begin{Def}
Схема Бернулли -- последовательность независимых испытаний в одинаковых условиях.    
\end{Def}

\begin{Rem}
Иными словами, это последовательность выборов с возвращениями.
Если выбор без возвращений, то это схема Лапласа.
\end{Rem}

Обычно следят за двумя исходами: событие $A$ произошло (успех) или не произошло (неудача) и рассматривают следующую величину:
$P_{n,p}(k) = P$(ровно $k$ успехов в $n$ испытаниях), $p$ -- вероятность успеха.

\begin{theorem}
    $P_{n,p}(k) = {n \choose k} p^k (1-p)^{n-k}$
\end{theorem}
\begin{proof}
    $\Omega = \{0, 1\}^n, |\Omega| = 2^n$ (1 -- успех, 0 -- неудача)

    $P(\{1, 1, 0, 1, 0, \dots \}) = p \cdot p \cdot q \cdot p \cdot q \cdot \dots = p^{a}q^{b}$, где $a, b$ -- число успехов и неудач соответственно.
    Наше событие состоит из ${n \choose k}$ таких равновероятных точек, по аддитивности получаем нужную вероятность.
\end{proof}                                                                  

\begin{Def}
Соответствующее разбиение называется биноминальным.
\end{Def}

Вариант для схемы с $m$ исходами: $P_{n, \bar p}(\bar k) = C_n^{k_1, \dots, k_m} \cdot p_1^{k_1} \cdot \dots \cdot p_m^{k_m}$


Можно посмотреть как зависит $P(k)$ от $k$. Можно понять, что $P(k) < P(k + 1)$ если $k < np + q$ (можно например подставить в формулу и проверить).

Говорят, что наиболее вероятное число успехов равно $np$. Это число, понятное дело, не является целым, но ближайшее целое число к нему будет наиболее вероятным.

Иногда хочется как-то приближенно оценить $P(k)$, для этого есть следующие две теоремы:
\begin{theorem}[Муавра-Лапласа, локальная]
Рассмотрим $a_k = \dfrac{e^{-\frac{(k - np)^2}{2}}}{\sqrt{2\pi npq}}$. Тогда
$$\sup_{k\colon |k - np| = o(n^{\frac23})} |\frac{P(k)}{a_k} - 1| \to 0$$
\end{theorem}
\begin{proof}
Без доказательства
\end{proof}
