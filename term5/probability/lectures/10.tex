\begin{theorem}[Неравенство Берри-Эссена]
$\xi_n -- iid$. Тогда $\sup |F_{\xi_n} - \Phi(x)| \leq C \frac{E |\xi_1 - a|}{\sigma^3 \sqrt{n}}$, где $\Phi \sim N(0, 1)$.
\end{theorem}

\subsection{Метод обратной функции}
\begin{exmp}
Основной метод для моделирования -- метод обратной функции, который уже разбирался ранее.

Его можно обобщить на многомерный случай: есть распределние в $\R^n$, хотим построить $\overrightarrow{\xi}$ c этим распределением.

Рассмотрим для этого последовательность функций 
\begin{gather*}
F_1(x_1) = F_{\xi_1}(x_1) \\
F_2(x_1, x_2) = F_{\xi_2} (x_2 \mid \xi_1 = x_1) \\
\dots \\
F_n(x_1, \dots, x_n) = F_{\xi_n} (x_n \mid \xi_1 = x_1, \dots, \xi_{n-1} = x_{n-1}) \\
\end{gather*}     
И последовательность равномерных независимых величин $\eta_k \sim U[0, 1]$.

Тогда $\xi$ -- решение следующей системы:
$\begin{cases}
F_1(\xi_1) = \eta_1 \\
F_2(\xi_1, \xi_2) = \eta_2 \\ 
\dots \\
F_n(\xi_1, \dots, \xi_n) = \eta_n
\end{cases}$

Доказательство аналогично одномерному случаю, но возни больше. Можно попробовать доказать до двух, а потом применить индукцию.
\end{exmp}

\begin{exmp}
Есть монетка, хотим выбрать с ее помощью одного человека из 10.
Проблема в том, что умеем получать равновероятно числа до степени двойки, а по-другому -- не особо.

Можно завести 6 ``фейков'', получится 16 человек, бросаем монетку 4 раза. Если попали в фейк, то еще раз пробуем, иначе заканчиваем процесс.

Аналогично, можно получить конечные рациональные числа.
\end{exmp}
\begin{exmp}
Похожая идея в методе Монте-Карло: хотим посчитать площадь фигуры, для этого моделируем распределение на каком-то прямоугольнике, в котором лежит наша фигура (так как саму фигуру замоделировать сложно).
\end{exmp}
\begin{exmp}
Моделирование смесей.

$F(x) \sum\limits_k C_k F_k(x), \sum C_k = 1$.

Предполагаем, что умеем моделировать случайные величины для $F_k$.

Замоделируем $\theta \colon P(\theta = k) = C_k$ -- какая-то дискретная величина.

Ну а теперь бросаем $\theta$, если выпало $k$, то генерим $\xi_k$ и возвращаем его.
Простой подстановкой получаем, что сгенерили именно нужное распределение.
\end{exmp}

\section{Еще предельные теоремы}
Законы ``0 или 1''.

Одну теорему уже знаем -- теорема Бореля-Кантелли о том, что вероятность того, что произойдет бесконечно много событий из какой-то последовательности, равна либо 0 либо 1.

Еще теоремка:
\begin{theorem}
Есть независимые $\xi_n$, $\mathcal{F}_n$ -- $\sigma$-алгера событий, определяемых значениями $(\xi_n,\xi_{n+1}, \dots)$.
Хвостовой $\sigma$-алгеброй назовем $\mathcal{X} = \bigcap\limits_{n=1}^\infty \mathcal{F}_n$

Иначе говоря, $\mathcal{F}_n$ -- события, про которые можно понять, исходя из значений $\xi_n$


Тогда $\forall A \in \mathcal{X} \colon P(A) = \begin{cases} 0 \\ 1 \end{cases}$
\end{theorem}
\begin{exmp}
В частности, ряд из независимых случайных величин либо почти всегда сходится, либо почти всегда расходится.
\end{exmp}

\begin{theorem}[Закон повторного логарифма]
$\xi_n$ -- iid с $E \xi_1 = 0, D\xi_1 = \sigma^2, S_n = \xi_1 + \dots + \xi_n$.

Тогда $P(\bar {\lim\limits_{n \to \infty}} \frac{S_n}{\sqrt{2 \sigma^2 n \ln \ln n}} = 1) = 1$.
\end{theorem}                                                                               
\begin{Rem}
Это значит, что если мы ``ограничим'' себя значением $(1 - \epsilon)$ на этот корень, то мы границу пересечем бесконечное число раз.
Если ограничим значением $(1 + \epsilon)$ на корень, то с каког-то момента границу пересекать не будем.

Поэтому, вот эту вот оценку называют точной верхней границей для случайного блуждания.
\end{Rem}

\begin{theorem}[Закон арксинуса]

$\xi_k$ -- независимые случайные величины = $\begin{cases} 1, \frac12 \\ 0, \frac12 \end{cases}$, $S_n = \sum\limits_1^n \xi_k$ -- стандартное случайное блуждание.

$\nu_n = \frac1n |\{k \leq n  \mid S_k > 0 \} |$ -- доля времени, когда лидируют гербы в серии бросков монетки.

Тогда $F_{\nu_n}(x) \xlongrightarrow[n \to \infty]{} \frac{2}{\pi} \arcsin \sqrt{x}, 0 \leq x \leq 1$ и $p_{\nu_n}(x) \xlongrightarrow[n \to \infty]{} \frac{1}{\pi \sqrt{x(1-x)}}$
\end{theorem}

\begin{theorem}[Эрдеш, Реньи]
Пусть есть $n$ бросков честной монетки, $\xi_n$ -- длина самой длинной серии гербов. Тогда $P(\xi_n \geq \log_2 n) \xlongrightarrow[n \to \infty]{} 1$
\end{theorem}
\begin{Rem}
Это еще одна точная оценка, можно как в законе повторного логарифма домножить на $(1 \pm \epsilon)$
\end{Rem}

\section{Еще пара результатов}
\begin{Def}
$\vec{\xi} = N(\vec{a}, B)$, если $p_\xi (x) = \frac{\sqrt{\det A}}{(2\pi)^{\frac{n}{2}}} e^{-\frac12 (x - a)^TA(x - a)}$, где
$\vec{a}$ -- вектор средних, $B$ -- матрица ковариаций, $A = B^{-1}$.

Характеристическая функция будет равна $f_\xi(t) = e^{i(t, a) - \frac12(Bt, t)}$
\end{Def}

Свойства:
\begin{enumerate}
\item Определяется 1 и 2 моментами (это и есть, собственно, вектор средних и матрица ковариаций)
\item Некоррелируемость равносильна независимости (некоррелируемость = матрица ковариаций диагональная, обратная тоже, экспонента распадется в произведение экспонент)
\end{enumerate}
\begin{exmp}
В двумерном случае, положительно определенная матрица ковариаций задаст эллипс
\end{exmp}
Стандартное нормальное распределение: $N(0, E)$.

Упражнение: пусть $\xi_1, \xi_2 \sim N(0, 1)$, независимы.
$\begin{cases} \xi_1 = \rho \cos \phi \\ \xi_2 = \rho \cos \phi \end{cases}$.
Тогда   
\begin{enumerate}
\item $D(\rho^2 \mid \text{точка на биссектрисе } x = y) = D(\xi_1^2 + \xi_2^2 \mid \xi_1 = \xi_2) = D(2\xi_1^2) = 4 D(\xi_1^2)$
\item $D(\rho^2 \mid \phi = \frac{\pi}{4} \text{ или } \phi = \frac{5\pi}{4})$.
Так как $\rho$ и $\phi$ независимы, то $ = D\rho^2 = D(\xi_1^2 + \xi_2^2) = 2D(\xi_1^2)$.
\end{enumerate}
Вопрос: как так?

Задача: есть забег, все бегуны равны по силе (имеют одинаковое распределение времени, когда финишируют).
Хотим понять какое время будет у золота, серебра, бронзы, и так далее. Эта задача называется задачей распределения порядковых статистик.

$\xi_k$ -- независимы, одинаково распределены, есть непрерывная функция распределения $F(x)$    

Упорядочим их по возрастанию, новый порядок будем индексировать со скобочками: $\xi_{(1)} \leq \xi_{(2)} \leq \dots \leq \xi_{(n)}$.

$\xi_{(k)}$ называется $k$-й порядковой статистикой.

\begin{gather*}
F_{\xi_{(k)}}(x) = P(\text{по крайней мере } k \text{ штук } \xi_j \text{ меньше } x) = \sum\limits_{j=k}^n P(\text{ровно } j \text{ с.в., меньших } x) = \\
= \sum\limits_{j=k}^n {n \choose j} F(x) (1 - F(x))^{n-j}
\end{gather*}

В частности, $F_{\xi_{(n)}} = F^n(x); F_{\xi_{(1)}} (x) = 1 - (1 - F(x))^n$.

А если есть производная, то $F'_{\xi_{(k)}}(x) = k {n \choose k} F^{k-1}(x)(1 - F(x))^{n-k}$. Просто если это честно посчитать, то по цепочке все сократится.