\section{} % 25
Линейный функционал "--- линейное отображение $V \to K = K^1$, полностью определяется значениями на базисе $V$.
$V*$ (двойственное пространство) "--- пространство линейный функционалов.
Пусть есть базис $v_i$ у $V$, тогда $v_i*$ в $V*$ (где соответствующий функционал 1 на $v_i$ и 0 на остальных) "--- базис $V*$.
Проверили, что образующие и что независимы.
То есть у них совпадают размерности, тогда в конечномерном случае они изоморфны.
Можно выбрать базис в $V$ и построить по базису $V$ какое-то линейно независимое множество в $V*$, в конечномерном случае оно окажется базисом (ура, изоморфизм явно построен).
Замечание: если $V=K^n$, то всякий линейный функционал есть скалярное произведение некоторого фиксированного $u$ и аргумента.

\section{} % 26
$V**$ "--- взяли двойственное к $V*$ (условно: $V*$ "--- всякого рода функции, $V**$ "--- всякого рода интегралы от функций).
Хотим построить отображение $u \to \phi_u \colon V \to V**$.
Определим линейный функционал $\phi_u(f)=f(u)$ для $V* \to V$ (надо проверить, что он линеен по своему аргументу "--- $f$).
Теперь говорим, что отображаем $u \in V$ в функционал $\phi_u$, который является элементом $V**$ (если ему скормить что-то из $V*$, он выдаст элемент $K$, как и надо).
Покажем, что это отображение линейно по $u$.
То есть имеем линейный гомоморфизм $V \to V**$.

Покажем, что он инъективен, для этого достаточно проверить тривиальность ядра.
$\phi_u = 0$ для некоторого $u$ $\iff$ $\forall f \in V* \colon (\phi_u(f) = 0 \iff f(u)=0)$.
Если $u \neq 0$, то можно дополнить $\{ u \}$ до базиса $V$ и найти специальное $f \in V*$, которое на $u$ будет $\neq 0$.
Если $V$ конечнопорождённое, то $\dim V = \dim V* = \dim V**$, а размерность образа тоже равна $n$, значит, имеем изоморфизм, а не просто вложение.

Пример: рассмотрим пространство последовательностей, где почти все члены ноль.
Рассмотрим функционалы вида <<скалярное произведение аргумента с последовательностью $B$>>.
Они линейны, все разные, их хотя бы $2^{|V|}$, то есть $|V*|\ge2^{|V|}$, что много (если $V$ счётно, то $V*$ несчётно).

\section{} % 27
Линейный оператор "--- линейное $f \colon V \to V$ ($End(V)$ "--- их пространство, эндоморфизмов).
Собственное число/вектор (в бесконечномерном тоже): пара $(\lambda, v)$ такая, что $f(v)=\lambda v$, $v$ отвечает числу $\lambda$.
Собственные вектора, отвечающие $\lambda$ образуют подпространство $U_1(\lambda) \le V$.
$\lambda$ "--- собственное число $\iff$ $\dim U_1(\lambda) > 0$.

Теперь рассмотрим квадратную матрицу $A$ для оператора (переводит вектор-столбец $X$ в $AX$), у неё аналогичным образом определили собственное число и вектор.
Условие на собственность: $AX=\lambda X$.
Характеристический многочлен $\chi$ матрицы $A$: $\det (A - tE) \in K[t]$.
Теорема: характеристический многочлен отображения $\chi_f$ не зависит от выбора базиса для матрицы (расписали определитель для матрицы $C^{-1}AC$, повыносили, сократилось).
Следствие: сумма диагональных элементов сохраняется (коэффициент при $t^{n-1}$), называется след (trace)ю
Собственные числа "--- в точности корни $\chi_f(t)$, так как совпадают с собственными числами $A$, а там можно решить уравнение $AX =\lambda X \iff AX-\lambda EX \iff (A-\lambda E)X = 0$
(матрица слева от $X$ квадратна и вырождена).
Далее везде будем считать, что $\chi_f$ раскладывается на множители ($K$ алгебраически замкнуто):
$\chi_f(t) = \chi_A(t) = (-1)^n \prod (t - \lambda_i)^{a_i}$, $\lambda_i$ попарно различны.
Тогда $a_i$ "--- алгебраическая кратность числа, а $\dim U_1(\lambda_i) = b_i$ "--- геометрическая.

В конечномерном $f$ диагонализуем, если существует базис, в котором матрица диагональна.
Теорема: $f$ диагонализуем $\iff$ есть базис из собственных векторов.
$\Ra$: взяли какой-то базис $v_i$, в котором матрица диагональна (на диагонали $\lambda_i$), тогда вектор $v_i$ собственный и отвечает $\lambda_i$ (подставили).
$\La$: взяли базис из собственных, составили такую же матрицу, значения на базисе какие надо, т.е. успех.

Замечание: не всё диагонализуемо.
Если одно собственное число и геометрическая кратность меньше алгебраической, то плохо.
Например, взяли $\begin{pmatrix}1&1\\1&1\end{pmatrix}$.

\section{} % 28
Пусть $f \in End(V)$, тогда $f^0 = id$, $f^k = \underbrace{f \circ f \circ \dots \circ f}_{f\text{~штук}}$.
Что такое сумма операторов, понятно, можно теперь вводить многочлен от оператора:
если $H=a_0+a_1t + \dots + a_kt^k$, то $H(f)=a_0 id + a_1 f + a_2 (f\circ f) \dots + a_k f^k \in End(V)$.
Складывать многочлены точно умеем (так что определение не портится), а вот умножать "--- не очень.
Покажем, что $H_1(f) \circ H_2(f) = (H_1H_2)(f) = (H_2H_1)(f) = H_2(f) \circ H_1(f)$
Для простых степеней $f$ всё ок, дальше домножаем многочлен на степень $f$ (тоже ок), потом раскрываем произведение многочленов.

\section{} % 29
Прямая сумма подпространств $U \oplus W$, если пересекаются тривиально (только по нулю).
Подпространство $U$ называется $f$-инвариантным, если $f(U) \subset U$.
Если $\lambda$ "--- собственное число, то $U_1(\lambda)$ $f$-инвариантно.
Теорема: если $V = U \oplus W$ и $U$ "--- $f$-инвариантно, то в любом базисе, где первая часть из $U$, а вторая из $W$ матрица $f$ имеет хороший вид: левый нижний кусок занулился.
Если оба инвариантны, то и правый верхний кусок занулился (получили два блока на диагонали).
Доказательство: просто посмотрели на образы этих базисных векторов, получили матрицу.
Следствие: если $V$ разложилось в прямую сумму $f$-инвариантных подпространств, то в каждом можно выбрать базис и получить блочно-диагональную матрицу.

\section{} % 30
В конечномерном: если есть эндоморфизм $f$ и многочлен $H \in K[t]$, то $\ker H(f)$ и $\Im H(f)$ есть $f$-инвариантные подпространства.
Взяли $U=\Im H(f)$, взяли $u \in U$, применили $f(H(f)(u)) = H(f)(f(u)) \in \Im H(f) = U$.
С ядром аналогично: $u \in \ker H(f)$, покажем, что $f(u)$ в ядре: $H(f)(f(u)) = f(H(f)(u))$, а $H(f)(u)$ ноль (так как $u$ в ядре), т.е. $H(f)(f(u))=f(0)=0$.
Замечание: если $f$ обратимо, то ядро тривиально, образ покрывает пространство и тогда для любого многочлена $H$ имеем $\Im H(f) = V$, $\ker H(f) = \{0\}$.

\section{} % 31
Хотим найти такой $H$, чтобы $\ker H(f)$ был как можно больше.
Больше $V$ не бывает, давайте найдём так, чтобы $\ker H(f) = V \iff H(f) = 0$.
Теорема Гамильтона-Кэли: в конечномерном $\chi_f(f) = 0$.
Зафиксировали базис, перешли к матрице (характеристический многочлен прежний), надо показать, что результатом будет нулевая матрица.
$\chi_A=\det (A - tE)$, нашли $B$ "--- взаимную к $A-tE$ (из алгебраических дополнений, почти обратная): $(A-tE)B=B(A-tE)=(\det(A-tE))E$.
Каждое алгебраическое дополнение есть многочлен степени не больше $n-1$, разложили $B$ по степеням $t$ в $B_0+tB_1+\dots$.
Разложили $\chi_A=a_0+a_1t+\dots$, приравняли коэффициенты при степенях $t$ ($AB_k-B_{k-1}=a_kE$), сложили с коэффициентами $A^0$, $A^1$, $A^2$, слева всё сократилось,
справа получили $\chi_A(A)$.

Многочлен называется аннулятором, если $H(f) = 0$, это множество "--- идеал в кольце главных идеалов $K[t]$, то есть порождается некоторым минимальным аннулятором $\mu_f$.
Например, для $f=\lambda id$ минимальным (одним из) будет $t-\lambda$, а не $(\lambda - t)^n$.

\section{} % 32
Если два многочлена $H_1$ и $H_2$ взаимно просты (отсюда полезное $1=G_1H_1+G_2H_2$), то $\ker (H_1H_2)(f) = \ker H_1(f) \oplus H_2(f)$.
Доказательство:
показали, что каждое из слагаемых справа лежит слева;
пересечение слагаемых тривиально (по представлению НОДа),
каждый вектор слева представляется как сумма справа (пользуемся тем же, в конце первое слагаемое лежит в $\ker H_2(f)$, второе "--- в $\ker H_1(f)$).
Тогда если $H(t)=\prod H_i(t)$, где они попарно взаимно просты, то $\ker H(f) = \bigoplus \ker H_i(f)$.
Если поле $K$ алгебраически замкнуто и пространство конечномерно, то можно разложить характеристический многочлен (ядро которого равно $V$)
на множители вида $(t-\lambda_i)^{a_i}$, они взаимно просты, разложили $V$ в прямую сумму корневых (см. дальше).
$k$-корневое пространство, отвечающее $\lambda$ есть $U_k(\lambda) \ker (f-\lambda id)^k$.
При этом цепочка пространств, отвечающих числу, вложена (так как $(f-\lambda id)(0)=0$) и стабилизируется (потому что при изменении растёт размерность, а она ограничена сверху).
Есть $U(\lambda) = \cup U_k(\lambda)$ (просто корневое пространство).
Корневой вектор "--- лежащий в неком $U_k(\lambda)$.
Если при этом он не лежит в $U_{k-1}(\lambda)$, то он высоты $k$.

\section{} % 33
Ввели Жорданову клетку: $\mathcal{J}_k(\lambda)=E_k+\mathcal{J}_k(0)$ (при нуле "--- единицы над диагональю).
В алгебраическом замкнутом поле для эндоморфизма $f$ имеется Жорданов базис, в котором матрица (Жорданова форма) имеет блочно-диагональный вид,
каждый блок "--- клетка, представление единственно с точностью до порядка блоков.
Число клеток, отвечающих $\lambda$, есть геометрическая кратность; суммарный размер "--- алгебраическая кратность $\lambda$.
Отсюда следует, что геометрическая кратность не больше алгебраической.
Даже когда у нас единственное собственное число, возможны разные конфигурации Жордановых клеток: $7=3+2+2=3+3+1$ (одинаковая алгебраическая и геометрическая кратности, одинаковая максимальная размерность, но разные формы).

Мы сначала сделаем для форм с единственным собственным числом, а потом разобъём в прямую сумму корневых, у каждого из которых будет одно собственное число.
Доказательство: сузили оператор $f$ на $U_{a_i}(\lambda_i)$, предположили существование другого собственного ичсла $\gamma$, показали обратимость оператора $f-\gamma id=f-\lambda id +(\lambda - \gamma)id$.
Для этого поделили на $\lambda - \gamma$, получили тождественное минус $g$ ($g^{a_i}=0$), а это обратимо: $(id-g)(id+g+\dots+g^{a_i-1})=id$.

\section{} % 34
Семейство $v_i$ линейно независимо относительно подпространства $U < V$, если $u + \sum a_i v_i = 0$ только при $a_i=0$.
Относительное семейство образующих, если либой $v \in V$ можно представить такой суммой.
Относительный базис "--- и то, и то (относительно одного и того же $U$).
Лемма: пусть $r \ge 2$, есть $u_1, \dots, u_s \in U_r(\lambda)$ (линейно независимы относительно $U_{r-1}(\lambda)$.
Тогда если мы подействуем на них оператором $f-\lambda id$, то мы получим вектора из $U_{r-1}(\lambda)$, которые будут линейно независимы относительно $U_{r-2}(\lambda)$.

Сначала показали, что лежат в $U_{r-1}(\lambda)$ по определению (проверили, что лежит в ядре): применили оператор много раз, занулилось.
Независимость от противного: пусть зависимы, тогда какая-то сумма ноль, подействовали оператором $(r-2)$ раза, одно слагаемое занулилось,
остальные внеслись под скобку и их сумма оказалась из $U_{r-1}(\lambda)$, а относительно него они линейно независимы, противоречие.

\section{} % 35
Рисуем красивую схему: взяли относительный базис $U_m(\lambda)$ относительно $U_{m-1}(\lambda)$, спустили вниз при помощи $f-\lambda id$ (остались линейно независимы), достроили до очередного относительного базиса.
Каждый относительный базис пишем в следующую строчку.
Все вектора из этой диаграммы Юнга будут давать базис $V$.
Теперь прочитали не по строкам, а по столбцам (сверху вниз).
Подпространства, порождённые столбцами, не пересекаются (они из разных векторов базиса $V$) и расделают $V$ в прямую сумму из них.
Взяли такое подпространство, выписали для него матрицу преобразования (используя лемму и тот факт, что каждый следующий "--- спущенный предыдущий), получили Жорданову клетку (для последнего надо знать, что он собственный вектор).
Параметр $m$ есть максимальный размер, количество клеток равно геометрической кратности (количеству векторов в базисе $U_1(\lambda)$).
Можно выразить количество клеток размера $\ge k$ (это $\dim U_k(\lambda) - \dim U_{k-1} (\lambda)$, отсюда "--- ровно $k$ю
Получаем <<вогнутость>> разменостей, а также то, что количества клеток не зависят от выбранных базисов (только от размерностей пространств).
Алгебраическая кратность "--- вроде очевидно.

\section{} % 36
Вычисление $A^m$ ($C^{-1}$ и $C$ в середине сокращаются, клетки возводятся в степень независимо, Жорданова клетка возвоздится в степень по биному Ньютона, а $\mathcal{J}_k(0)$ возводится очень просто).
Можно быстро вычислить значение $g(t) \in K[t]$ в матрице $A$ (тот же принцип).

Определение:
$\exp(A) = \sum_{k=0}^\infty \frac{A^k}{k!}$ (смотрим на это как на $n^2$ рядов, соответствующих элементам).
Каждый ряд должен сходиться: пусть $M=\max |a_{ij}|$, тогда оценили $|(A^k)_{ij} \le n^{k-1}M^k \le (nM) ^ k$, то есть каждый элемент оценили как сумма <<полином делить на факториал>>, что (почти) ряд для экспоненты.
То есть определение осмысленно.
А быстро вычисляется при помощи Жордановой формы потому что в каждом слагаемом $C^{-1}$ и $C$ выносятся за скобки.
