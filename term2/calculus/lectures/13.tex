\setauthor{Егор Суворов}

\begin{theorem}
	Пусть есть многомерная функция $f \colon D \subseteq \R^n \to \R$.
	$f$ $(r+1)$ раз непрерывно дифференцируема в $D$.
	Также есть отрезок $[x, x_0] \subseteq D$ (отрезок по прямой).
	\cautoimg{13_segment}
	Тогда можно написать формулу (здесь $k$ "--- мультииндексы):
	\[ f(x) = \sum_{|k| \le r} \frac{f^{(k)}(x_0)}{k!} (x - x_0)^k + \sum_{|k| = r + 1} \frac{f^{(k)}(x_0+\theta(x-x_0))}{k!} (x-x_0)^k\]
\end{theorem}
\begin{proof}
	Возьмём $F \colon [0, 1] \to \R$ такое: $F(t)=f(x_0+t\underbrace{(x-x_0)}_{h})$.
	Это обычная функция из $[0, 1]$ в $\R$, она дифференцируема $r+1$ раз (так как все точки отрезка $[x, x_0]$ лежат в $D$).
	Напишем формулу Тейлора для неё:
	\[ F(1) = \sum_{l=0}^r \frac{F^{(l)}(0)}{l!} \cdot 1^l + \frac{F^{(r+1)}(\theta)}{(r+1)!} \cdot 1 ^ {r+1}\]
	Вспомним нашу последнюю лемму, которая выражает $l$-ю производную $F$:
	\[ F^{(l)}(t) = \sum_{|k| = l} \frac{l!}{k!} f^{(k)}(x_0+th) h^k\]
	Теперь подставим это дело в формулу Тейлора для $F$:
	\begin{align*}
		F^{(l)}(0) &= \sum_{|k| = l} \frac{l!}{k!} f^{(k)}(x_0) h^k \\
		F^{(l)}(\theta) &= \sum_{|k| = l} \frac{l!}{k!} f^{(k)}(x_0 + \theta h) h^k \\
		F(1) &= \sum_{l=0}^r \sum_{|k| = l} \frac{1}{k!} f^{(k)}(x_0) h^k + \sum_{|k| = r + 1} \frac{1}{k!} f^{(k)}(x_0 + \theta h) h^k \\
		     &= \sum_{|k| \le r} \frac{f^{(k)}(x_0)}{k!} h^k + \sum_{|k| = r + 1} \frac{f^{(k)}(x_0 + \theta h)}{k!} h^k \\
	\end{align*}
\end{proof}
\begin{Rem}
	$\sum_{|k|\le r} \frac{f^{(k)} (x_0)}{k!} (x - x_0) ^ k$ "--- многочлен Тейлора степени $r$.
\end{Rem}
\begin{Rem}
	Если $r=0$, то получим многомерную формулу Лагранжа:
	\[f(x) = f(x_0) + \sum_{i=1}^n \partd{f}{x_i} (x_0+\theta h) \cdot h_i = f(x_0) + \left< \nabla f(x_0+\theta h), h \right>\]
\end{Rem}
\begin{conseq}
	Формула Тейлора с остатком в форме Лагранжа:
	\[ f(x_0 + h) = f(x_0) + \left< \nabla f (x_0+\theta h), h \right> \]
\end{conseq}
\begin{Rem}
	Формула Тейлора при $n=2$ и произвольном $r$ (двумерный случай) в точке $(x_0, y_0)$ с сдвигом $(h, k)$:
	\begin{align*}
		f(x_0+h, y_0+k)
			&= f(x_0, y_0)
			+ \partd{f}{x}(x_0, y_0)h + \partd{f}{y}(x_0, y_0)k + \\
			&+ \frac12\left(
				\partdd{f}{x}{x} (x_0, y_0) h^2
				+ 2\partdd{f}{x}{y} (x_0, y_0) hk
				+  \partdd{f}{y}{y} (x_0, y_0) k^2
			\right) + \\
			&+ \dots
			 + \frac{1}{    l!} \sum_{i=0}^l     \Choose{l  }{i} \frac{\partial^l     f}{\partial x^i \partial y^{l  -i}} (x_0, y_0)                   h^i k^{l  -i}
			 + \dots + \\
			&+ \frac{1}{(r+1)!} \sum_{i=0}^{r+1} \Choose{r+1}{i} \frac{\partial^{r+1} f}{\partial x^i \partial y^{r+1-i}} (x_0+\theta h, y_0+\theta k) h^i k^{r+1-i}
	\end{align*}
\end{Rem}

\begin{theorem}
	Формула Тейлора с остатком в форме Пеано:
	\[ f(x_0+h) = \sum_{|k|\le r} \frac{f^{(k)}(x_0)}{k!} h^k + o(\|h\|^r) \text{~при~} \|h\| \to 0\]
\end{theorem}
\begin{proof}
	Выпишем формулу из последней теоремы (только уменьшим $r$ на единицу для удобства):
	\begin{align*}
		f(x+h) &= \sum_{|k|\le r-1} \frac{f^{(k)}(x_0)}{k!} h^k + \sum_{|k|=r}\frac{f^{(k)}(x_0+\theta h)}{k!}h^k = \\
		       &= \sum_{|k|\le r  } \frac{f^{(k)}(x_0)}{k!} h^k + \sum_{|k|=r}\frac{f^{(k)}(x_0+\theta h)-f^{(k)}(x_0)}{k!}h^k
	\end{align*}
	Надо оценить вторую сумму.
	Так как там слагаемых конечное количество, достаточно оценить каждое слагаемое.
	Пусть у нас имеется мультииндекс $(k_1, \dots, k_n)$, причём $\sum k_i = r$.
	На $k!$ тоже забьём, это константа:
	\begin{gather*}
		\left(f^{(k)}(x_0+\theta h) - f^{(k)} (x_0)\right) \frac{h^k}{\|h\|^r} \stackrel{?}{\to} 0 \text{~при~} h \to 0 \\
		\left(f^{(k)}(x_0+\theta h) - f^{(k)} (x_0)\right) \to 0 \\
		\frac{h^k}{\|h\|^r}
			= \frac{h_1^{k_1}h_2^{k_2}\dots h_n^{k_n}}{\|h\|^r}
			= \frac{h_1^{k_1}h_2^{k_2}\dots h_n^{k_n}}{\|h\|^{k_1}\|h\|^{k_2}\dots\|h\|^{k_n}}
			= \prod_{i=1}^{n} \frac{h_i^{k_i}}{\|h\|^{k_i}} \\
		\frac{|h^k|}{\|h\|^r}
			= \prod_{i=1}^{n} \frac{|h_i|^{k_i}}{\|h\|^{k_i}}
			\le 1 \\
		(\to 0) \cdot (\le 1) \to 0
	\end{gather*}
\end{proof}

\begin{theorem}[Полиномиальная формула]
	\[
		\left(\sum_{i=1}^n x_i\right)^r = \sum_{|k|=r} \frac{r!}{k!} x^k = \sum_{k_1+k_2+\dots+k_n=r}\Choose{r}{k_1, \dots, k_n}
			x_1^{k_1}x_2^{k_2}\dots x_n^{k_n}
	\]
	где
	\[ \frac{r!}{k!} = \frac{r!}{k_1!k_2!\dots k_n!} = \Choose{r}{k_1, k_2, \dots, k_n}\]
	(мультиномиальный коэффициент).
\end{theorem}
\begin{proof}
	Можно по индукции, это несложно.
	Но давайте лучше жахнем из формулы Тейлора.
	Пусть
	\[ f(x)=\left( \sum_{i=1}^n x_i \right)^r \]
	Найдём его частную производную по $x_i$:
	\begin{gather*}
		\partd{f}{x_i} (x) = r \left( \sum_{i=1}^n x_i \right)^{r-1} \\
		\frac{\partial ^ l f}{\partial x_{i_1} \dots \partial x_{i_l}} (x) = r(r-1)(r-2)\dots(r-l+1) \left( \sum_{i=1}^n x_i \right)^{r-l} \\
	\end{gather*}
	Посмотрим на неё в точке $x=0$.
	При $l>r$ у нас остаток точно занулится (потому что встретится множитель ноль).
	При $l<r$ у нас остаток тоже занулится (так как последний множитель есть ноль в ненулевой степени).
	А при $l=r$ остаток получится равен $r!$.

	Подставляем в формулу Тейлора с остатком в форме Лагранжа ($x_0=0$):
	\[
		f(h)
			= \underbrace{\sum_{|k| \le r} \frac{f^{(k)}(0)}{k!} h^k}_{=0\text{~при~}|k|<r}
			+ \underbrace{\sum_{|k|=r+1} \frac{f^{(k)}(\theta h)}{k!} h^k}_{=0}
			= \sum_{|k|=r} \frac{r!}{k!} h^k
	\]
\end{proof}

\section{Экстремумы функций}
\begin{Def}
	$f \colon D \subseteq \R^n \to \R$ и $a \in D$.
	Говорим, что $a$ "--- точка минимума, если $\exists U$ "--- открытая окрестность $a$ такая, что
	\[ \forall x \in U \cap D \colon f(x) \ge f(a) \]
\end{Def}
\begin{Rem}
	Можно аналогично определить $a$ "--- точка максимума.
\end{Rem}
\begin{Def}
	Говорим, что $a$ "--- точка строгого минимума, если $\exists \mathring U$ "--- проколотая открытая окрестность $a$ такая, что
	\[ \forall x \in \mathring U \cap D \colon f(x) > f(a) \]
\end{Def}

Дальше будем учиться по производным делать какие-то выводы о наличии экстремумов в точках.
По тому, что хочется "--- полная аналогия с одномерным случаем.
По тому, что получится "--- намного больше наворотов.

\begin{theorem}[Необходимое условие экстремума]
	$f \colon D \subseteq \R^n \to \R$ и $a \in \Int D$.
	Если $a$ "--- точка экстремума (максимума/минимума) и $\partd{f}{x_i}$ существует в точке $a$,
	то $\partd{f}{x_i}(a)=0$.
\end{theorem}
\begin{Rem}
	В частности, если $f$ дифференцируема в точке $a$, то $\nabla f(a) = 0$.
\end{Rem}
\begin{Rem}
	На самом деле, если $f$ дифференцируема, то у нас производная по
	любому направлению обращается в ноль.
	Но они все выражаются через $\partd{f}{x_i}$, поэтому про них говорить излишне.
\end{Rem}
\begin{proof}
	Пусть $a$ "--- максимум.
	Взяли какую-нибудь окрестность из определения максимума, пересечём её с множеством $D$
	(в определении не требовалось $U \subseteq D$).
	Рассмотрим одну координату $x_k$.
	Положим $\phi(t)=f(a_1, \dots, a_{k-1}, t, a_{k+1}, \dots a_n)$.
	Тогда, очевидно, $a_k$ "--- точка максимума для $\phi(t)$,
	так как $\phi$ "--- это просто сужение $f$ на прямую.
	А если есть частная производная по $x_k$, то $\phi$ дифференцируема.
	По одномерной теореме $\phi'(a_k)=0$, то есть $\partd{f}{x_k}(a)=0$.
\end{proof}

\begin{Def}
	$a$ "--- стационарная точка, если $\nabla f(a) = 0$.
\end{Def}

Теперь хотим узнавать, какие из стационарных точек являются экстремумами.
В одномерном случае была такая же проблема: там были <<сёдла>>.
Мы решали эту проблему, написав многочлен Тейлора до следующего слагаемого.
Попробуем порассуждать здесь так же.

Давайте возьмём стационарную точку и напишем многочлен Тейлора до второго слагаемого.
Выглядит она вот так:
\[
	f(a+h) = f(a) + \frac12 \sum_{i,j=1}^n \partdd{f}{x_i}{x_j} (a) h_i h_j + o(\|h\|^2)
\]
\begin{proof}
	\[ f(a+h) = f(a) + \sum_{|k|=2} \frac{f^{(k)}(a)h^k}{k!} + o(\|h\|^2)\]
	У нас бывают мультииндексы двух типов:
	\begin{enumerate}
	\item
		$k=(0, \dots, 0, 2, 0, \dots, 0)$.
		Тогда у нас это слагаемое встретится в исходной сумме один раз и в знаменателе будет $k!=2!=2$.
		То есть выносится коэффициент $\frac12$.
	\item
		$k=(0, \dots, 0, 1, 0, \dots, 0, 1, 0, \dots, 0)$.
		Это слагаемое встретится в исходной сумме два раза (для $(i, j)$ и для $(j, i)$)
		вместо одного, но в знаменателе будет $k!=1!\cdot1!=1$.
		То есть тоже выносится коэффициент $\frac12$.
	\end{enumerate}
\end{proof}
Теперь надо убедиться, что остаток везде имеет одинаковый знак.

\subsection{Квадратичные формы}
\begin{Def}
	Пусть $C$ "--- симметричная матрица $n \times n$.
	Тогда квадратичная форма $Q(h) \colon \R^n \to \R$ по матрице $C$ есть:
	\[ Q(h) = \sum_{i,j=1}^n c_{i,j} h_i h_j \]
\end{Def}
\begin{Rem}
	Если $h$ "--- вектор-столбец, то $Q(h) = h^\top C h$.
	Но мы этим пользоваться не будем.
\end{Rem}
\begin{Def}
	$Q$ "--- строго положительно определённа, если
	\[ \forall h \neq 0 \colon Q(h) > 0\]
\end{Def}
\begin{Rem}
	Аналогично можно определить нестрого положительно определённую.
	И отрицательно определённые.
\end{Rem}
\begin{exmp}
	Если $C=E$, то у нас получается строго положительно определённая форма,
	потому что $Q(h) = \sum h_i^2$.
\end{exmp}

\begin{theorem}[Критерий Сильвестра]
	% картинка с Сильвестром
	Пусть есть матрица
	\[
	С=
	\begin{pmatrix}
		c_{11} & c_{12} & c_{13} & \dots \\
		c_{21} & c_{22} & c_{23} & \dots \\
		\vdots & \vdots & \vdots & \ddots
	\end{pmatrix}
	\]
	Рассмотрим определители:
	\begin{gather*}
	\det
		\begin{pmatrix}
			c_{11}
		\end{pmatrix} \\
	\det
		\begin{pmatrix}
			c_{11} & c_{12} \\
			c_{21} & c_{22} \\
		\end{pmatrix} \\
	\det
		\begin{pmatrix}
			c_{11} & c_{12} & c_{13} \\
			c_{21} & c_{22} & c_{23} \\
			c_{31} & c_{32} & c_{33} \\
		\end{pmatrix} \\
	\vdots \\
	\det C
	\end{gather*}
	Строгая положительная определённость эквивалентна тому, что
	все эти определители строго больше нуля.
	Для нестрогого "--- нестрого.
\end{theorem}
\begin{Rem}
	Будет когда-нибудь доказано на алгебре.
\end{Rem}
\begin{Rem}
	Чтобы сказать что-то для отрицательной определённости, надо рассмотреть матрицу $-C$.
	Определители поменяют знаки в зависимости от чётности размера аргумента.
\end{Rem}

\subsection{Связь экстремумов и квадратичных форм}
\begin{theorem}
	$f \colon D \subseteq \R^n \to \R$ и $a \in \Int D$.
	Пусть $f$ дважды непрерывно дифференцируема в окрестности точки $a$, и $a$ "--- стационарная точка.
	Пишем квадратичную форму
	\[
		Q(h) = \sum_{i,j=1}^n \partdd{f}{x_i}{x_j} (a) h_i h_j
	\]
	\begin{itemize}
	\item Если $Q$ "--- строго положительно определённая, то $a$ "--- строгий минимум
	\item Если $Q$ "--- строго отрицательно определённая, то $a$ "--- строгий максимум
	\item Если $a$ "--- нестрогий минимум, то $Q$ нестрого положительно определена
	\item Если $a$ "--- нестрогий максимум, то $Q$ нестрого отрицательно определена
	\end{itemize}
\end{theorem}
\begin{Rem}
	Есть некоторая свобода.
	Может получиться так, что форма нестрого определена, а экстремума нет.
	Такая же проблема бывала и в одномерном случае: когда у нас вторая производная обращалась в ноль,
	приходилось работать головой и руками в каждом отдельном случае.
\end{Rem}
