\setauthor{Егор Суворов}

\begin{theorem}
	Пусть есть многомерная функция $f \colon D \subseteq \R^n \to \R$.
	$f$ $(r+1)$ раз непрерывно дифференцируема в $D$.
	Также есть отрезок $[x, x_0] \subseteq D$ (отрезок по прямой).
	% картинка загогулины, отрезок попадает внутрь, не попадает внутрь
	Тогда можно написать формулу (здесь $k$ "--- мультииндексы):
	\[ f(x) = \sum_{|k| \le r} \frac{f^{(k)}(x_0)}{k!} (x - x_0)^k + \sum_{|k| = r + 1} \frac{f^{(k)}(x_0+\theta(x-x_0))}{k!} (x-x_0)^k\]
\end{theorem}
\begin{proof}
	Возьмём $F \colon [0, 1] \to \R$ такое: $F(t)=f(x_0+t\underbrace{(x-x_0)}_{h})$.
	Это обычная функция из $[0, 1]$ в $\R$, она дифференцируема $r+1$ раз (так как все точки отрезка $[x, x_0]$ лежат в $D$).
	Напишем формулу Тейлора для неё:
	\[ F(1) = \sum_{l=0}^r \frac{F^{(l)}(0)}{l!} \cdot 1^l + \frac{F^{(r+1)}(\theta)}{(r+1)!} \cdot 1 ^ {r+1}\]
	Вспомним нашу последнюю лемму, которая выражает $l$-ю производную $F$:
	\[ F^{(l)}(t) = \sum_{|k| = l} \frac{l!}{k!} f^{(k)}(x_0+th) h^k\]
	Теперь подставим это дело в формулу Тейлора для $F$:
	\begin{align*}
		F^{(l)}(0) &= \sum_{|k| = l} \frac{l!}{k!} f^{(k)}(x_0) h^k \\
		F^{(l)}(\theta) &= \sum_{|k| = l} \frac{l!}{k!} f^{(k)}(x_0 + \theta h) h^k \\
		\vdots
	\end{align*}
\end{proof}
\begin{Rem}
	$\sum_{|k|\le r} \frac{f^{(k)} (x_0)}{k!} (x - x_0) ^ k$ "--- многочлен Тейлора степени $r$.
\end{Rem}
\begin{Rem}
	Если $r=0$, то получим многомерную формулу Лагранжа:
	\[f(x) = f(x_0) + \sum_{i=1}^n \partd{f}{x_i} (x_0+\theta h) \cdot h_i = f(x_0) + \left< \nabla f(x_0+\theta h), h \right>\]
\end{Rem}
\begin{conseq}
	Формула Тейлора с остатком в форме Лагранжа:
	\[ f(x_0 + h) = f(x_0) + \left< \nabla f (x_0+\theta h), h \right> \]
\end{conseq}
\begin{Rem}
	Формула Тейлора при $n=2$ и произвольном $r$ (двумерный случай) в точке $(x_0, y_0)$ с сдвигом $(h, k)$:
	\begin{align*}
		f(x_0+h, y_0+k)
			&= f(x_0, y_0)
			+ \partd{f}{x}(x_0, y_0)h + \partd{f}{y}(x_0, y_0)k + \\
			&+ \frac12\left(
				\partdd{f}{x}{x} (x_0, y_0) h^2
				+ 2\partdd{f}{x}{y} (x_0, y_0) hk
				+  \partdd{f}{y}{y} (x_0, y_0) k^2)
			\right) + \\
			&+ \dots
			+ \frac{1}{    l!} \sum_{i=0}^l     \Choose{l  }{i} \frac{\partial^l     f}{\partial x^i \partial y^{l  -i}} (x_0, y_0)                   h^i k^{l  -i} + \\
			&+ \dots
			+ \frac{1}{(r+1)!} \sum_{i=0}^{r+1} \Choose{r+1}{i} \frac{\partial^{r+1} f}{\partial x^i \partial y^{r+1-i}} (x_0+\theta h, y_0+\theta k) h^i k^{r+1-i}
	\end{align*}
\end{Rem}

\begin{theorem}
	Формула Тейлора с остатком в форме Пеано:
	\[ f(x_0+h) = \sum_{|k|\le r} \frac{f^{(k)}(x_0)}{k!} h^k + o(\|h\|^r) \text{~при~} \|h\| \to 0\]
\end{theorem}
\begin{proof}
	Выпишем формулу из последней теоремы (только уменьшим $r$ на единицу для удобства):
	\begin{align*}
		f(x+h) &= \sum_{|k|\le r-1} \frac{f^{(k)}(x_0)}{k!} h^k + \sum_{|k|=r}\frac{f^{(k)}(x_0+\theta h)}{k!}h^k = \\
		       &= \sum_{|k|\le r  } \frac{f^{(k)}(x_0)}{k!} h^k + \sum_{|k|=r}\frac{f^{(k)}(x_0+\theta h)-f^{(k)}(x_0)}{k!}h^k
	\end{align*}
	Надо оценить вторую сумму.
	Так как там слагаемых конечное количество, достаточно оценить каждое слагаемое.
	Пусть у нас имеется мультииндекс $(k_1, \dots, k_n)$, причём $\sum k_i = r$.
	На $k!$ тоже забьём, это константа:
	\begin{gather*}
		\left(f^{(k)}(x_0+\theta h) - f^{(k)} (x_0)\right) \frac{h^k}{\|h\|^r} \stackrel{?}{\to} 0 \text{~при~} h \to 0 \\
		\left(f^{(k)}(x_0+\theta h) - f^{(k)} (x_0)\right) \to 0 \\
		\frac{h^k}{\|h\|^r}
			= \frac{h_1^{k_1}h_2^{k_2}\dots h_n^{k_n}}{\|h\|^r}
			= \frac{h_1^{k_1}h_2^{k_2}\dots h_n^{k_n}}{\|h\|^{k_1}\|h\|^{k_2}\dots\|h\|^{k_n}}
			= \prod_{i=1}^{n} \frac{h_i^{k_i}}{\|h\|^{k_i}} \\
		\frac{|h^k|}{\|h\|^r}
			= \prod_{i=1}^{n} \frac{|h_i|^{k_i}}{\|h\|^{k_i}}
			\le 1 \\
		(\to 0) \cdot (\le 1) \to 0
	\end{gather*}
\end{proof}

\begin{theorem}[Полиномиальная формула]
	\[
		\left(\sum_{i=1}^n x_i\right)^r = \sum_{|k|=r} \frac{r!}{k!} x^k = \sum_{k_1+k_2+\dots+k_n=r}\Choose{r}{k1, \dots, k_n}
			x_1^{k_1}x_2^{k_2}\dots x_n^{k_n}
	\]
	где
	\[ \frac{r!}{k!} = \frac{r!}{k_1!k_2!\dots k_n!} = \Choose{r}{k_1, k_2, \dots, k_n}\]
	(мультиномиальный коэффициент).
\end{theorem}
\begin{proof}
	Можно по индукции, это несложно.
	Но давайте лучше жахнем из формулы Тейлора.
	Пусть
	\[ f(x)=\left( \sum_{i=1}^n x_i \right)^r \]
	Найдём его частную производную по $x_i$:
	\begin{gather*}
		\partd{f}{x_i} (x) = r \left( \sum_{i=1}^n x_i \right)^{r-1} \\
		\frac{\partial ^ l f}{\partial x_{i_1} \dots \partial x_{i_l}} (x) = r(r-1)(r-2)\dots(r-l+1) \left( \sum_{i=1}^n x_i \right)^{r-l} \\
	\end{gather*}
	Посмотрим на неё в точке $x=0$.
	При $l>r$ у нас остаток точно занулится (потому что встретится множитель ноль).
	При $l<r$ у нас остаток тоже занулится (так как последний множитель есть ноль в ненулевой степени).
	А при $l=r$ остаток получится равен $r!$.

	Подставляем в формулу Тейлора с остатком в форме Лагранжа ($x_0=0$):
	\[
		f(h)
			= \underbrace{\sum_{|k| \le r} \frac{f^{(k)}(0)}{k!} h^k}_{=0\text{~при~}|k|<r}
			+ \underbrace{\sum_{|k|=r+1} \frac{f^{(k)}(\theta h)}{k!} h^k}_{=0}
			= \sum_{|k|=r} \frac{r!}{k!} h^k
	\]
\end{proof}
% конец параграфа

\section{Экстремумы функций}
\begin{Def}
	$f \colon D \subseteq \R^n \to \R$ и $a \in D$.
	Говорим, что $a$ "--- точка минимума, если $\exists U$ "--- открытая окрестность $a$ такая, что
	\[ \forall x \in U \cap D \colon f(x) \ge f(a) \]
\end{Def}
\begin{Rem}
	Можно аналогично определить $a$ "--- точка максимума.
\end{Rem}
\begin{Def}
	Говорим, что $a$ "--- точка строгого минимума, если $\exists \mathring U$ "--- проколотая открытая окрестность $a$ такая, что
	\[ \forall x \in \mathring U \cap D \colon f(x) > f(a) \]
\end{Def}

Дальше будем учиться по производным делать какие-то выводы о наличии экстремумов в точках.
По тому, что хочется "--- полная аналогия с одномерным случаем.
По тому, что получится "--- намного больше наворотов.

\begin{theorem}[Необходимое условие экстремума]
	$f \colon D \subseteq \R^n \to \R$ и $a \in \Int D$.
	Если $a$ "--- точка экстремума (максимума/минимума) и $\partd{f}{x_i}$ существует в точке $a$,
	то $\partd{f}{x_i}(a)=0$.
\end{theorem}
\begin{Rem}
	В частности, если $f$ дифференцируема в точке $a$, то $\nabla f(a) = 0$.
\end{Rem}
\begin{Rem}
	На самом деле, если $f$ дифференцируема, то у нас частная производная по
	любому направлению обращается в ноль.
	Но они все выражаются через $\partd{f}{x_i}$, поэтому про них говорить излишне.
\end{Rem}
\begin{proof}
	Пусть $a$ "--- максимум.
	Взяли какую-нибудь окрестность из определения максимума, пересечём её с множеством $D$
	(в определении не требовалось $U \subseteq D$).
	Рассмотрим одну координату $x_k$.
	Положим $\phi(t)=f(a_1, \dots, a_{k-1}, t, a_{k+1}, \dots a_n)$.
	Тогда, очевидно, $a_k$ "--- точка максимума для $\phi(t)$,
	так как $\phi$ "--- это просто сужение $f$ на прямую.
	А если есть частная производная по $x_k$, то $\phi$ дифференцируема.
	По одномерной теореме $\phi'(a_k)=0$, то есть $\partd{f}{x_k}(a)=0$.
\end{proof}

\begin{Def}
	$a$ "--- стационарная точка, если $\nabla f(a) = 0$.
\end{Def}

Теперь хотим узнавать, какие из стационарных точек являются экстремумами.
В одномерном случае была такая же проблема: там были <<сёдла>>.
Мы решали эту проблему, написав многочлен Тейлора до следующего слагаемого.
Попробуем порассуждать здесь так же.

Давайте возьмём стационарную точку и напишем многочлен Тейлора до второго слагаемого.
Выглядит она вот так:
\[
	f(a+h) = f(a) + \frac12 \sum_{i,j=1}^n \partdd{f}{x_i}{x_j} (a) h_i h_j + o(\|h\|^2)
\]
\begin{proof}
	\[ f(a+h) = f(a) + \sum_{|k|=2} \frac{f^{(k)}(a)h^k}{k!} + o(\|h\|^2)\]
	У нас бывают мультииндексы двух типов:
	\begin{enumerate}
	\item
		$k=(0, \dots, 0, 2, 0, \dots, 0)$.
		Тогда у нас это слагаемое встретится в исходной сумме один раз и в знаменателе будет $k!=2!=2$.
		То есть выносится коэффициент $\frac12$.
	\item
		$k=(0, \dots, 0, 1, 0, \dots, 0, 1, 0, \dots, 0)$.
		Это слагаемое встретится в исходной сумме два раза (для $(i, j)$ и для $(j, i)$)
		вместо одного, но в знаменателе будет $k!=1!\cdot1!=1$.
		То есть тоже выносится коэффициент $\frac12$.
	\end{enumerate}
\end{proof}
Теперь надо убедиться, что остаток везде имеет одинаковый знак.

\begin{Def}
	Пусть $C$ "--- симметричная матрица $n \times n$.
	Тогда квадратичная форма $Q(h) \colon \R^n \to n$ по матрице $C$ есть:
	\[ Q(h) = \sum_{i,j=1}^n c_{i,j} h_i h_j \]
\end{Def}
\begin{Rem}
	Если $h$ "--- вектор-столбец, то $Q(h) = h^\top C h$.
	Но мы этим пользоваться не будем.
\end{Rem}
\begin{Def}
	$Q$ "--- строго положительно определённа, если
	\[ \forall h \neq 0 \colon Q(h) > 0\]
\end{Def}
\begin{Rem}
	Аналогично можно определить нестрого положительно определённую.
	И отрицательно определённые.
\end{Rem}
\begin{exmp}
	Если $C=E$, то у нас получается строго положительно определённая форма,
	потому что $Q(h) = \sum h_i^2$.
\end{exmp}

\begin{theorem}[Критерий Сильвестра]
	% картинка с Сильвестром
	Пусть есть матрица
	\[
	С=
	\begin{pmatrix}
		c_{11} & c_{12} & c_{13} & \dots \\
		c_{21} & c_{22} & c_{23} & \dots \\
		\vdots & \vdots & \vdots & \ddots
	\end{pmatrix}
	\]
	Рассмотрим определители:
	\begin{gather*}
	\det
		\begin{pmatrix}
			c_{11}
		\end{pmatrix} \\
	\det
		\begin{pmatrix}
			c_{11} & c_{12} \\
			c_{21} & c_{22} \\
		\end{pmatrix} \\
	\det
		\begin{pmatrix}
			c_{11} & c_{12} & c_{13} \\
			c_{21} & c_{22} & c_{23} \\
			c_{31} & c_{32} & c_{33} \\
		\end{pmatrix} \\
	\vdots \\
	\det C
	\end{gather*}
	Строгая положительная определённость эквивалентна тому, что
	все эти определители строго больше нуля.
	Для нестрогого "--- нестрого.
\end{theorem}
\begin{Rem}
	Будет когда-нибудь доказано на алгебре.
\end{Rem}
\begin{Rem}
	Чтобы сказать что-то для отрицательной определённости, надо рассмотреть матрицу $-C$.
	Определители поменяют знаки в зависимости от чётности размера аргумента.
\end{Rem}

\begin{theorem}
	$f \colon D \subseteq \R^n \to \R$ и $a \in \Int D$.
	Пусть $f$ дважды непрерывно дифференцируема в окрестности точки $a$.
	Пишем квадратичную форму
	\[
		Q(h) = \sum_{i,j=1}^n \partdd{f}{x_i}{x_j} (a) h_i h_j
	\]
	\begin{itemize}
	\item Если $Q$ "--- строго положительно определённая, то $a$ "--- строгий минимум
	\item Если $Q$ "--- строго отрицательно определённая, то $a$ "--- строгий максимум
	\item Если $a$ "--- нестрогий минимум, то $Q$ нестрого положительно определена
	\item Если $a$ "--- нестрогий максимум, то $Q$ нестрого отрицательно определена
	\end{itemize}
\end{theorem}
\begin{Rem}
	Есть некоторая свобода.
	Может получиться так, что форма нестрого определена, а экстремума нет.
	Такая же проблема бывала и в одномерном случае: когда у нас вторая производная обращалась в ноль,
	приходилось работать головой и руками в каждом отдельном случае.
\end{Rem}

\setauthor{Дмитрий Лапшин}

\begin{lemma}
	Если $Q(h)$ "--- строго положительно определена, то существует $c > 0$, что
	\[ \forall h, Q(h) \ge c\|h\|^2 \]
\end{lemma}
\begin{proof}
	Рассмотирм $Q$ на единичной сфере. Получим непрерывную на компакте функцию, поэтому
	\begin{gather*}
		\exists h_0\colon \underbrace{Q(h_0)}_{>0} = \min \{Q(h)\} \lrh c \\
		Q(h) = Q\left(\|h\| \cdot \frac{h}{\|h\|}\right) = \|h\|^2 Q\left(\frac{h}{\|h\|}\right) \ge \|h\|^2 c
	\end{gather*}
\end{proof}

Докажем теперь теорему:
\begin{proof}
	\[ f(a + h) - f(a) = \frac12 \underbrace{\sum_{i,j = 1}^n \partdd{f}{x_i}{x_j}(a) h_ih_j}_{=Q(h)} + o(\|h\|^2) \]
	\begin{enumerate}
	\item
		$Q(h)$ "--- положительно определена, откуда $Q(h) \le c \|h\|^2$.
		\[  f(a+h) - f(a) = \frac12 Q(h) + o(\|h\|^2) \ge \frac{c\|h\|^2}2 + o(\|h\|^2) = \|h\|^2 \underbrace{\left(\frac{c}2 + o(1)\right)}_{\text{$>0$ при малых $h$}} \]

	\item $f \ra -f$

	\item
		$a$ нестрогий минимум, поэтому $f(a+h) \ge f(a)$ при достаточно малых $h$.
		Зафиксируем $h$ и будем рассматривать $f(a+th) \ge f(a)$ при достаточно малых $t$.
		\[ f(a+th) - f(a) = \frac12 \sum_{i,j = 1}^n \partdd{f}{x_i}{x_j}(a) t^2h_ih_j \underbrace{o(\|th\|^2)}_{=t^2o(1)} = \frac{t^2}2 Q(h) + t^2o(1)\]
		\[ 0 = \frac{f(a+th) - f(a)}{t^2} = \frac12 Q(h) + o(1) \]
		Переходим к пределу
		\[ \frac{f(a+th) - f(a)}{t^2} \ge 0 \]

	\item $f \ra -f$
	\end{enumerate}
\end{proof}

Дальше Тейлора выписывать не рекомендуют: вместо матриц выйдет табличка четырёхмерных коэффициентов.

\begin{Def}
	Гессиан или матрица Гессе "--- та самая матрица, квадратичную норму которой мы и смотрели:
	\[ \left( \partdd{f}{x_i}{x_j}\right)_{i,j=1}^n \]
\end{Def}

\section{Обратные отображения}

Ещё одна теорема больше из алгебры:
\begin{theorem}
	$A\colon \R^n \ra \R^m$ "--- линейный оператор. Тогда следующее равносильно:
	\begin{enumerate}
		\item $A$ обратим
		\item $A(\R^n) = \R^m$
		\item Уравнение $Ax = 0$ имеет нулевое решение
		\item $\det A \ne 0$
	\end{enumerate}
\end{theorem}
\begin{proof}
	Докажем не очень строго: перезапишем всё выше в терминах систем уравнений:
	\begin{enumerate}
		\item Для всех $y$ уравенние $Ax = y$ имеет единственное решение
		\item Для всех $y$ уравенние $Ax = y$ имеет решение
		\item Уравнение $Ax = 0$ имеет нулевое решение
		\item $\det A \ne 0$
	\end{enumerate}
	Получилось, что система линейных уравнений имеет единственное решение для любых свободных коэффициентов, в том числе для нулевых свободных коэффициентов "--- тривиальное, тогда и только тогда, когда определитель матрицы системы не ноль.
\end{proof}

\begin{theorem}
	$A\colon \R^n \ra \R^m$ "--- линейный оператор,
	\[ \exists m > 0\colon \forall x \in \R^n, \|Ax\| \ge m\|x\| \]
	Тогда $A$ обратим и $\left\|A^{-1}\right\| \le \frac1m$.
\end{theorem}
\begin{proof}
	\[ Ax = 0 \Ra 0 = \|Ax\| \ge m\|x\| \Ra x = 0 \]
	Смотрим теорему выше.
	\[ \left\|A^{-1}\right\| = \inf \left\{c > 0 \mid \left\|A^{-1} x\right\| \le c \|x\| \right\} \]
	Нам достаточно показать, что
	\[ \left\|A^{-1} x\right\| \le \frac{1}m \|x\| \]
	$y \lrh A^{-1} x$, $x = Ay$
	\[ \|y\| \le \frac{1}m \|Ay\| \]
	Это мы уже знаем
\end{proof}

\begin{Rem}
	\[ \forall x, \|Ax\| \ge \frac{1}{\left\|A^{-1}\right\|} \|x\| \]
\end{Rem}
\begin{proof}
	\begin{gather*}
		\left\| A^{-1} \right\| \|A x\| \ge \|x\| \\
		\|x\| = \left\|A^{-1} (Ax)\right\| \le \left\|A^{-1}\right\| \|A x\|
	\end{gather*}
\end{proof}

\begin{theorem}[Обратнимость линейных операторов, близких к обратимым]
	$A\colon \R^n \ra \R^m$ "--- обратимый линейный оператор, $\left\|A^{-1}\right\| = \frac1\alpha$.
	\begin{enumerate}
	\item
		Если $B\colon \R^n \ra \R^m$ "--- линейный оператор, $\|B - A\| = \beta < \alpha$, то $B$ обратим и
		\[ \left\|B^{-1} - A^{-1}\right\| < \frac{\beta}{\alpha(\alpha - \beta)} \]

	\item
		Пусть $\Omega$ "--- множество обратимых операторов. Тогда $f\colon B \ra B^{-1}$ непрерывна на $\Omega$.
	\end{enumerate}
\end{theorem}
\begin{proof}
	\begin{enumerate}
	\item
		\begin{gather*}
			\|Ax\| = \|Bx + (A-B)x\| \le \|Bx\| + \|(A - B)x\| \le \|Bx\| + \|(A - B)\| \|x\| = \|Bx\| + \beta \|x\| \\
			\|Ax\| \ge \frac{1}{\left\|A^{-1}\right\|} \|x\| = \alpha \|x\| \\
			(\alpha - \beta) \|x\| \le \|Bx\|
		\end{gather*}
		По предыдущей теореме уже получили обратимость.
		\begin{gather*}
			B^{-1} A^{-1} = B^{-1} (A - B) A^{-1} \\
			\left\|B^{-1} - A^{-1}\right\| = \left\|B^{-1} (A - B) A^{-1}\right\| \le \left\|B^{-1}\right\| \|A - B\| \left\|A^{-1}\right\|
				= \frac1{\alpha - \beta}\beta\frac1\alpha = \frac{\beta}{\alpha(\alpha - \beta)}
		\end{gather*}

	\item
		\[ B_k \ra A \Ra \|B_k - A\| \ra 0 \stackrel{?}{\Ra} \|B_k^{-1} - A^{-1}\| \ra 0 \Ra B_k^{-1} \ra A^{-1} \]
		$\left\|A^{-1}\right\| = \frac1\alpha$
		\begin{gather*}
			\|B_k - A\| \le \frac{\alpha}2 \\
			\left\|B_k^{-1} - A^{-1}\right\| \le \frac{\|B_k - A\|}{\alpha(\alpha - \|B_k - A\|)} \le \frac{2}{\alpha^2} \|B_k - A\| \ra 0
		\end{gather*}
	\end{enumerate}
\end{proof}

\begin{theorem}[Об обратной функции]
	$f\colon D \subset \R^n \ra \R^m$, $a \in \Int D$, $f$ непрерывно дифференцируема в окрестности $a$, $\d_a f$ "--- обратимое отображение, $b = f(a)$.
	Тогда
	\begin{enumerate}
	\item
		Существует окрестности $U$ точки $a$ и $V$ точки $b$, что $f\colon V \ra U$ "--- биекция.

	\item
		Пусть $g\colon V \ra U$ "--- обратная к $f$. Тогда $g$ "--- непрерывно дифференцируема.
	\end{enumerate}
\end{theorem}

\begin{Rem}
	В случае верности теоремы
	\[ g(f(x)) = x \]
	\[ \d_{f(x)} g \circ \d_x f = id \]
	\[ \d_{f(x)} g = \left(\d_x f\right)^{-1} \]
\end{Rem}

\begin{Rem}
	Это самая адовая теорема курса! Доказателсьтво длинное, разбито на важные шаги.
\end{Rem}

\begin{proof}
	\begin{enumerate}
	\item
		$A = \d_a f$. Выберем $\lambda\colon 4\lambda \|A^{-1}\| = 1$.
		В качестве $U$ возьмём шар с центром в $a$, что
		\[ \forall x \in U, \|\d_x f - \d_a f\| \le 2\lambda \]
		\begin{description}
		\item[Шаг 1:]
			Докажем, что $f$ инъективна на $U$.
			Возьмём две точки $x, x + h \in U$.
			Покажем, что значения $f(x)$ и $f(x + h)$ различны.
			В шаре содержится отрезок $[x, x + h]$.
			\begin{gather*}
				F\colon [0,1] \ra \R^n; F(t) = f(x+th) - tAh \\
				F'(t) = \d_{x+th} f(h) - Ah \\
				\|F(1) - F(0)\| \le \|F'(t)\| = \| \d_{x+th} f(h) - Ah\| \le \quad \text{при некотором $t$ по теореме Лагранжа} \\
				\le \underbrace{\|\d_{x+th} f - A\|}_{x + th \in U} \|h\| < 2\lambda \|h\| \\
				\begin{aligned}
					F(0) &= f(x) \\
					F(1) &= f(x + th) - Ah
				\end{aligned}\\
				\|f(x + th) - Ah - f(x)\| \le 2\lambda \|h\| = \frac{1}{2\left\|A^{-1}\right\|} \|h\| = \frac{\|Ah\|}2 \\
				\|f(x + th) - f(x) \| = \|f(x+th) - f(x) - Ah + Ah\| \ge \|Ah\| - \|f(x+h) - Ah - f(x)\| \ge \\
				\ge \|Ah\| - \frac{\|Ah\|}2 = \frac{\|Ah\|}2 \\
				f(x+h) = f(x) \Ra 0 \ge \frac{\|Ah\|}2 \Ra \|Ah\| = 0 \Ra h = 0
			\end{gather*}
			Таким образом, $f(x+h) \ne f(x)$.
		\end{description}
	\end{enumerate}
\end{proof}
