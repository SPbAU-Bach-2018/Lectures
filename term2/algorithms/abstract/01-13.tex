\section{} % 01
Бинарное может хранить детей (иногда еще родителя).
Можно хранить сына и брата.
Можно хранить список родителей для вершин.
Дерево поиска можно записать в прямом обходе (\t{x L R}) и хранить только ключи.

\section{} % 02
Если мы ищем следующий <<в лоб>>, это амортизированное $\O(1)$.
Можно добавить двусвязный список, будет честное $\O(1)$.
Можно делать \t{find} за $\O(1)$ хэш-таблицей.
Можно удалять за $\O(1)$, ставя пометку.
Всё, кроме \t{Insert} теперь умеем за честное $\O(1)$, а его быстрее нельзя, иначе слишком быстро отсортируем массив.

\section{} % 03
Вставили случайную перестановку наивно "--- случайное дерево.
Равносильно: выбираем случайный корень из элементов, рекурсивно.
Матожидание максимальной глубины дерева "--- $\O(\log)$.
Матожидание глубины "--- $\O(\log)$:
сначала показали, что сумма размеров поддеревьев равна сумме глубин,
а сумма размеров "--- это в точности время работы QuickSort.

\section{} % 04
Разница высот левого и правого не больше единицы, размер дерева хотя бы $F_h$.
Изменили вершину "--- сразу перебалансировали поворотом.
Они бывает обычные (когда глубокое поддерево слева-слева)
и большие (когда глубокое слева-справа, тогда мы его <<вытаскиваем>> наверх).
Нет, большие не получатся автоматически, надо отдельно разбирать, но через обычные выражаются.
Все операции так же, как в просто BST.
В \t{del} можно сделать \t{swap} себя с соседом справа, будет проще.

\section{} % 05
Сначала как-то научились фиксить дисбаланс $k$ за $\O(k)$. \TODO
\t{merge}: удалили у левого дерева крайний правый элемент, сделали его корнем результата, подвесили параметры, перебалансировали.
\t{split}: идём как в декартовом дереве, на каждом шаге делаем один дополнительный \t{merge}.

\section{} % 06
Пары $(x_i, y_i)$, по $x$ "--- BST, по $y$ "--- куча.
Если $y_i$ различны, то структура однозначна, выбираем их случайно, получили случайное BST.

\section{} % 07
Rope "--- интерфейс (есть еще одноимённая структура, но нам не задавали).
Хранит много цепочек, можно разрезать связь внутри цепочки, можно склеивать две, можно получать $k$-й элемент.
Это декартово дерево по неявному ключу и \t{reverse} на отрезке (проталкивания сверху).

\section{} % 08
Отсортированный список.
А над ними еще $\log$ слоёв, каждый из которых содержит какое-то подмножество элементов нижнего слоя.
В следующий слой элемент переходит с вероятностью $\frac 1 2$.
На ребре надо хранить его длину (и пересчитывать).
Сначала пытаемся пробираться по верхним уровням, если ускакали далеко "--- спускаемся ниже.
Матожидание длины ребра на уровне $k$ равно $2^k$.
Поэтому всё делаем за $\O(\log)$.
Для вставки/удаления элемент всегда нужно сначала найти (чтобы разорвать/создать связи из разных слоёв).

\section{} % 09
Персистентно "--- храним все предыдущие версии.
Можно в offline, обойдя дерево версий dfs'ом: при спуске делаем операцию, при подъёме откатываем.
Амортизация в операциях так может убиться.
Реализация: запрещаем что-либо менять, всегда создаём новую версию вершины.
Персистентный массив "--- персистентное декартово по неявному ключу.
Раз есть массив, можно вообще что угодно сделать персистентным за лишний $\O(\log)$.
Задача: есть массив, надо уметь считать сумму на отрезке, выводить отрезок и копировать
один фрагмент поверх другого (возможно, с пересечениями, но это неважно).
Аккуратно с памятью: можно либо регулярно перестраивать дерево с нуля, либо поддерживать
в вершинах счётчик ссылок (у скольки вершин она ребёнок), либо \t{shared\_ptr}.
Аккуратно с одинаковыми $y$: см. вопрос 11.

\section{} % 10
Persistent Stack "--- это просто односвязный список, версия "--- указатель на голову.
\TODO

\section{} % 11
Почти декартово.
Надо не хранить $y$, а в \t{merge} заменить их сравнение на случайный выбор с весами
(чтобы сохранилось свойство про случайность корня).
Тогда проблем с персистентностью нет.
Пример, когда есть: кучу раз копируем одну и ту же вершину.
Построение за $\O(n)$: идём по ключам слева направо, храним в стеке <<самые правые вершины дерева>>,
в зависимости от <<виртуального $y$>> удаляем вершины из стека, потом привешиваем.

\section{} % 12
B-дерево: детей у вершины (кроме корня) $[k, 2k)$ или $[k,2k]$ (2-3-дерево "--- частный случай).
Добавление: добавили вершину в лоб, потом поднимаемся и, возможно, распиливаем родителя на двух,
у дедушки появляется плюс одна вершина.
Удаление ключа: если из листа, то иногда надо перетащить себе ключик из соседа (или слиться с ним).
Если из внутренней вершины, то иногда надо удалить рекурсивно из какого-то ребёнка ключ и забрать его себе.
RB-дерево: вершины двух цветов, все листья чёрные и на одинаковой чёрной глубине,
две красные не соединяются (если объединить красные с родителями, получим 2-3-4 дерево).
AA-дерево: как RB-дерево к 2-3-4 дереву: у чёрной не бывает двух красных детей.

\section{} % 13
Пусть заранее известно, какие вершины и с какой частотой будут запрашиваться ($k_i$).
Надо построить такое дерево поиска, чтобы $\sum k_i depth_i \to \min$.
Динамика по подотрезкам, сначала за куб (выбираем корень).
Потом трюк с оптимальным положением корня: $p_{L,R-1} \le p_{L,R} \le p_{L+1,R}$.
Итого квадрат.
