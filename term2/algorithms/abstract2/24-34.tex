\section{} % 24
Период бывает целый и нецелый, еще бывает минимальный.
Период можно найти z-функцией и линейным проходом: проверили, что $lcp(s, s + k) = |s|-k$, тогда $k$ "--- период.
Бойер-Мур: прикладываем сначала шаблон в начало строки (слева направо), но сравниваем всё справа налево, тогда можно на какие-то символы в $s$ вообще не смотреть.
Эвристика стоп-символа: если у нас не сошлось и в строке $s$ был символ $x$, то надо сдвинуть шаблон до самого правого символа $x$ в шаблоне (раньше бессмысленно).
Эвристика суффикса: если с конца совпало $k$ элементов, то надо сдвинуть шаблон так, чтобы на том, что уже сматчилось, шаблон совпадал.
Это можно предподсчитать префикс-функцией от перевёрнутого шаблона: если совпало $k$ символов, то надо сдвинуться до первого места, где префикс-функция стала равна $k$.
Работает алгоритм хорошо, если не валить, иначе "--- за квадрат.

\section{} % 25
Рабин-Карп: если хэш случаен, то вероятность коллизии на одном прикладывании $\frac{1}{MOD}$, это мало, можно честно при коллизии проверять и время работы линейно (если остановиться после первого вхождения).
LCP подстрок можно либо предподсчитать за квадрат времени и памяти (этакая динамика в лоб), либо искать бинпоиском и хэшами.
Тогда можно за это же время сравнивать лексикографически "--- по первому несовпавшему символу.
Тогда суфмассив "--- это сортировка со специальным компаратором.

\section{} % 26
Бинпоиск по длине ответа плюс найти совпадающие хэши (и можно даже честно проверить, мы же после первого ОК остановимся).
Для $k$ строк можно хранить хэш-таблицу только для подстрок первой, тогда $\O(n)$ памяти.
LCS "--- максимум из LCP.
Через суфдерево/автомат: написали \t{s\#t \$}, надо найти глубокую вершину, из которой можно достичь и \t{\#}, и \t{\$}, ей соответствует некоторая общая подстрока.

\section{} % 27
Алгоритм Манакера "--- ищем палиндромы одной чётности (для каждого центра "--- максимальная длина палиндрома отсюда), почти как z-функция.
Вместо него можно делать бинпоиск из каждого центра и сравнивать хэшами.
Дерево палиндромов: вершина "--- уникальный палиндром, переходы по букве "--- дописали её слева и справа, два корня (для чётных/нечётных),
суфссылка "--- максимальный суффикс-подпалиндром).
Дописываем по одному символу, в каждый момент храним максимальный суффикс-подпалиндром.
Прыгаем по суфссылкам, пока не совпадёт символ, потом иногда создаём новую вершину (в неё суфссылка ищется в лоб "--- путь до результата мы больше проходить не будем).

\section{} % 28
Внутри вершины можно хранить переходы в: массиве, \t{map}, \t{unordered\_map}, списки (не лучше \t{map}), <<не храни ничего, если не больше одного ребра>>, splay (тогда будет почему-то не $\O(L\log)$, а $\O(L + \log)$.
Сжатое ST: $\O(n)$ вершин (каждая вершина "--- развилка), из дерева можно получить массив (dfs'ом выписали листья), из массива и LCP можно получить дерево (добавляем суффиксы от меньших к большим, знаем, какой длины создавать очередное ребро или куда подниматься).

\section{} % 29
Взяли бор из шаблонов, суфссылка ведёт как в префикс-функции.
Считать их так: по уровням, берём суфссылку из родителя и прыгаем по суфссылкам, пока на найдём свой символ.
Время работы не больше суммарной длины всех шаблонов (что может быть сильно больше размера бора, конечно).
Потом прошлись по haystack, каждый раз у нас глубина вершины либо уменьшается, либо увеличивается на 1 (как в КМП), почти успех.
Вхождения-то могут быть и не в текущей вершине, поэтому чтобы выводить все, надо еще пробегаться по суфссылкам из текущей вершины (надо предподсчитать, куда прыгать до вхождения, чтобы делать это быстро).
Полный автомат: просто из каждой вершины считаем все переходы и суфссылку, после чего следующие суфссылки тоже считаются за константу.
Больше памяти, зато честное $\O(1)$ на каждый переход.
Ленивое построение: как полный автомат, на заранее вообще ничего не считаем, полезно, если у нас все вхождение обрубаются наверху дерева.

Поиск статистики для шаблонов: для каждой вершины бора считаем, в каких позициях мы туда приходили.
Берём дерево суфссылок и для каждого шаблона смотрим в поддерево: на каких позициях заканчивалось это слово.
Online суммарное количество вхождений: надо для вершины предподсчитать количество вхождений вверх по суффиксному пути.

\section{} % 30
Суфссылки в сжатом боре ведут всегда из вершин в вершины.
Если у нас есть ребро в лист, то говороим, что оно бесконечное, чтобы вообще не беспокоиться об их продлении.
Храним указатель на конец самого длинного суффикса, который заканчивается не в листе (возможно, на ребре).
Дописали в конец строки символ "--- листья продлились сами, этот длинный суффикс надо продлить, прыгнуть по суфссылке, повторить.
В какой-то момент обнаружим, что такая вершина уже есть, надо остановиться, дальше прыгать бессмысленно: переход никуда не денется.
Суфссылки у новых вершин проставляются очевидно.
Итого мы с каждым символом либо добавляем вершину и прыгаем, либо останавливаемся, итого $\O(n)$ (считая алфавит константой).

\section{} % 31
К строке можно дописать хрень, начнут сортироваться суффиксы, а не циклические сдвиги.
Можно повторить два раза, начнут сортироваться циклические сдвиги вместо суффиксов.
Построение SA: $\log n$ шагов, на каждом отсортированы циклические сдвиги длиной $2^k$ (у каждого сдвига есть класс эквивалентности, по которым их можно сравнивать), на шаге сортируем цифровой сортировкой сдвиги следующей длины.
Но это нестабильная сортировка (если есть одинаковые циклические сдвиги), надо в конце еще раз отсортировать цифровой по парам $\langle color, i \rangle$.
Алгоритм Касаи: вычисляем LCP в порядке уменьшения длин суффиксов, при откусывании символа от двух суффиксов их LCP лишь уменьшился на единицу.
Для циклических сдвигов надо аккуратнее рассмотреть, когда порядок $x<y$ не нарушается при откусывании символа (нарушается константу раз в специфичных случаях, тогда сбрасываем текущий LCP).

\section{} % 32
Сортируем суффиксы.
Есть строчка длины $n$, сжали символы до алфавита из $n$.
Разбили на тройки символов, строчку можно записать либо как $A_0=w_0w_3w_6$, либо без первого символа: $A_1=w_1w_4\dots$, либо без двух первых ($A_2$).
Вызвались рекурсивно от строки длины $\frac{2n}{3}$ \t{$A_0$\#$A_1$}, отсортировали суффиксы все, кроме как для позиций $3k+2$.
Теперь за линию отсортируем суффиксы строки $A_2$, каждый такой "--- это символ плюс суффикс $A_0$.
Осталось за линию смёржить два массива, надо сравнивать суффиксы.
Они либо одного типа, либо типы отличаются на единицу, тогда можно откусить не более двух символов так, чтобы они стали типов 0 и 1, тогда можно сравнивать.
Итого $T(n) = \O(n) + T(\frac23 n) = \O(n)$.

\section{} % 33
Если модуль и основание выбирать случайно среди нескольких, то анти-хэш тест строить не умеем (две разные строки с одинаковыми хэшами).
Для модуля $2^k$ и произвольного основания $P$ можно взять короткие куски строки Туэ-Морса (вычли два хэша, получили произведение вида $(P^1-1)(P^2-1)(P^4-1)(P^8-1)\dots$, оно занулилось).
Для $\langle P, MOD \rangle$: хотим найти знакопеременную сумму из $P^0$, $P^1$, $P^2$, \dots, $P^{k-1}$ (возможно, с пропусками).
Взяли сначала просто значения, отсортировали, взяли разности в парах (стало $\frac n 2$ значений, чтобы коэффициенты были $\pm 1$), потом повторили, и так, пока не нашли ноль.
Считаем, что изначально были случайные числа от $0$ до $MOD$.
Потом считаем, что если было $k$ случайных чисел от $0$ до $x$, то после разностей будет $\frac k 2$ случайных чисел от $0$ до $\frac{x}{k+1}$.
То есть после нескольких итераций значения будут от $0$ до $\frac{MOD}{(k+1)(k/2+1)(k/4+1)\dots}$, можно оценить $\log k$ как $\sqrt{2\log MOD}$.

Пусть $P$ "--- точка, $MOD$ "--- модуль, $S$ "--- многочлен (скажем, разность двух строк) с коэффициентами до $MOD-1$, $k$ "--- его степень.
Лемма 1: если многочлен случаен, то вероятность $S(P)=0$ равна $\frac{1}{MOD}$, так как поделили на $(x-p)$, остаток случаен.
Лемма 2: если точка случайна, то при простом $M$ у нас не более $k$ корней, т.е. вероятность $\le \frac{k}{MOD}$, а если $MOD=2^{32}$, то может быть и $2^{31}$ корней у $x^{32}=0$.
Лемма 3: если оба случайны, то тоже $\frac{1}{MOD}$, так как по лемме 1 для \textit{любой} точки вероятность попасть многочленом равна $\frac{1}{MOD}$, значит, неважно, что точка тоже теперь случайна.
Кстати, получилось, что в среднем у многочлена один корень.
Выбираем простой модуль и случайное $P$.

\section{} % 34
Пусть $m$ списков, $n$ чисел.
Матожидание длины списка "--- $\frac{n}{m} = 1$.
Матожидание максимума при $n=m$ "--- $\O(\log n)$, доказательство: вероятность того, что длина ячейки равна $k$ есть
$\frac{\binom{n}{k}(n-1)^{n-k}}{n^n} \le \frac{n^kn^{n-k}}{k!n^n} = \frac{1}{k!}$
Вероятность того, что хотя бы одно $Len_i \ge k$ есть $n(\frac{1}{k!}+\frac{1}{(k+1)!}+\dots) \le {2n}{k!}$ (потому что поделили и ряд сошёлся).
Например, при $k = \log n$ вероятность будет мала, но матожидание максимума мы не оценивали.

Двойное хэширование: берём два хэша, добавляем в ту ячейку, где короче, тогда матожидание максимальной длины будет $\Theta (\log \log n)$ (без доказательства).
Совершенное: хотим со статичными значениями найти идеальную хэш-функцию для $m=n^2$.
Берём случайную и проверяем (вероятность коллизии не более $\frac{n(n-1)}{2} \cdot \frac{1}{m} \le \frac 12$, быстро повезёт).
Теперь чтобы не делать квадрат памяти, на первом уровне взяли какую-нибудь хэш фукнцию, а внутри каждой ячейке вместа списка длины $a_i$ делаем совершенную хэш-функцию и храним $a_i^2$ памяти.
Матожидание $\sum a_i^2$ есть матожидание числа коллизий, что меньше $2n$.
Лемма Маркова: $E[X] \le A \Ra Pr[A \ge 2X] \le \frac 12$, то есть нам потребуется больше $4n$ памяти с вероятностью меньше $\frac 12$.

Фильтр Блюма: есть $m$ бит памяти, можно добавлять элементы, можно спрашивать <<верно ли, что точно нет?>> (может иногда сказать <<да>>, даже если не добавляли).
При добавлении считаем $k$ хэш-функций, в $k$ ячейках ставим единицы.
Оценка ошибки очевидно высчитывается через количество добавленных элементов $x$, $k$ и $n$: нам плохо, если на каждое из $k$ мест когда-то записался хотя бы один из случайных $xk$ бит.
