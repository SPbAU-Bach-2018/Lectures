\section{} % 35
Есть начальная вершина, ходят по очереди, проигрывает, кто не может ходить.
Чей ход "--- неважно, вершины одинаковые.
На ацикличном бывают проигрышные/выигрышные, можно dfs'ом-динамикой понять.
Ретроанализ "--- такой bfs наоборот, который ставит WIN/LOSE, что-то может не поставить до конца.
Что не поставил "--- DRAW (выигрышной стратегии нет ни у кого).
Длина игры: можно сказать, что проигрывающий хочет проигрывать как можно дольше, а выигрывать хотят побыстрее.
Это можно считать прямо внутри ретроанализа, вершины мы будем обходить по возрастанию <<длины игры>>.
Еще бывают поддавки (задача с легендой про котят), когда проигрывать хотят как можно быстрее.
Тогда надо сначала посчитать выигрышность/проигрышность, а вот вторым bfs'ом считать длину (иначе с выигрышными мы можем пропустить хороший длинный ход).

Пусть есть игра на бинарном дереве (ходим вниз), тогда если идти сначала в случайного ребёнка и сразу обрубать при переходе в проигрышную позицию, то будет $\O(1.687^h)$ вместо $\O(2^h)$,
независимо от распределения WIN и LOSE: пишем матожидание времени работы в зависимости от высоты и выигрышности, вычисляем.

\section{} % 36
Гранди от позиции в ацикличных играх: mex (minimal excluded number) от функций Гранди переходов.
Ноль $\iff$ позиция проигрышна.
Можно вычислять в лоб: вычислили для детей вершины, сложили их значения в хэш-таблицу, делаем \t{f++}, пока не нашли mex (всего \t{++} будет не больше детей).
Для прямой суммы (где мы делаем ход в ровно одной из двух игр): функция есть XOR функций от игр.
Любое меньшее XOR'а можно получить: посмотрели на первое место, где XOR отличается от искомого, выбрали нужный ход в одной из игр.
А вот сам XOR не получить, потому что ходим ровно в одной игре.

Карлсон: есть трёхмерная шоколадка $a \times b \times c$, за ход делим на две, съедаем больший кусок.
По каждом измерению игра независима, успех.
Жестокая задача: убираем по очереди из последовательности элементы, если у элемента не оказалось соседей, он тоже убирается.
После хода игра превращается в прямую сумму двух игр, считаем Гранди и успех.

\section{} % 37
Можно or, and, xor, not, сдвиги, считать количество бит.
Рюкзак: \t{f |= f << a[i]} по очереди для всех элементов.
Умножение, деление многочленов, Гаусс "--- очевидно (плюс есть xor).
Умножение матриц "--- одну надо транспонировать.
Флойд "--- вынесли одно из условий на второй уровень вложенности с третьего, внутри получили \t{|=}.
Можно еще сжать компоненты сильной связности за $\O(n+m)$, а потом динамику достижимости на ацикличном графе, будет быстрее на разреженных графах.

\section{} % 38
Пусть умножаем матрицы над $F_2$.
Разрежем первую матрицу на вертикальные(!) полоски $a_i$, вторую "--- на горизонтальные $b_i$, все ширины $k$.
Произведение $a_ib_j$ имеет размер $n \times n$, результат равен сумме всех таких $a_ib_j$.
Научимся вычислять такое произведение за $\O(n^2)$: $i$-я его строчка есть сумма каких-то строк из $b_j$, каких "--- характеризуется строкой $a_i$.
Предподсчитаем для каждого $b_j$ все $2^k$ возможных сумм, для всех $b_j$ будет за $\O(\frac{nk2^k}{k})$.
Положим $k=\log n$, получим $\O(n^2)$ на предподсчёт, а произведение $a_ib_j$ знаем за $\O(nk)$.
Все произведения можем вычислить и сложить за $\O(\frac{n^2}{k^2} \cdot nk) = \O(\frac{n^3}{\log n})$.

Хотим построить схему вычисления булевой функции от $n$ переменных.
Переведя в КНФ/ДНФ, можно получить $\O(n2^n)$, можно по одной убивать переменные: $f(\dots, x_{n-1}, x_n) = (x_n \& f(\dots, x_{n-1}, 1)) | (!x_n \& f(\dots, x_{n-1}, 0))$, будет $\O(2^n)$.
Предподсчитаем все функции от первых $1$, $2$, \dots, $k$ переменных (следующие выражаются через предыдущие), места займут $2^{2^k} + 2^{2^{k-1}} + \dots = \O(2^{2^k})$.
Теперь за размер $\O(2^{n-k})$ убьём последние $n-k$ переменных, останутся $k$, они предподсчитаны для всех функций.
Возьмём $k=\log n - 1$, итого $\O(2^{2^k} + 2^{n-k})=\O(2^{n/2}+\frac{2^n}{n})=\O(\frac{2^n}{n})$.

\TODO Наибольшая общая подпоследовательность.

Еще пример: Фарах-Колтон-Бендер.

\section{} % 39
$\O(nmk)$ "--- количество строк на ширину строки на ранг.
К треугольному быстрее, к диагональному чуть дольше.
Для лучшей точности полезно брать максимальный по модулю элемент из угла матрицы, а не просто какой попадётся.
Точность может теряться сильно (матрица Гильберта: $a_{ij}=\frac{1}{i+j}$.
Решение СЛУ: просто делаем все операции еще и со столбцом свободных переменных.
Обратная матрица: делаем все операции и со строками единичной матрицы, в конец привели исходную в единичную, а старая единичная стала обратной.
Как на практике по алгебре.

\section{} % 40
По одному нормализуем вектора сверху вниз: взяли очередной, вычли из него предыдущие с коэффициентами (чтобы скалярное произведение занулилось), отнормировали.
Дополнение базиса: взяли случайный, проверили, что он линейно независим, должно повезти.
Проверка вектора: либо убедились в линейной зависимости, либо ортогонализировали базис и разложили.
Расстояние от точки до подпространства: ортогонализировали базис, вычли из точки проекции на базисные, получили нормаль к пространству.
\TODO второй метод

\section{} % 41
Делить нельзя, но можно пользоваться алгоритмом Евклида для каждой пары строк, чтобы занулять одну из них, определитель тогда не меняется.
К диагональному виду не привести, но к треугольному "--- можно (так как алгоритм Евклида будет применяться для строк одинаковой длины).
А в $\Z$ тоже можно, но числа будут расти экспоненциально.

\section{} % 42
Есть ориентированный граф, на рёбрах "--- вероятности перехода из вершины по ребру,
начинаем в стартовой, где окажемся с какой вероятностью через $k$ шагов?
Можно динамикой за $\O(kE)$, можно возвести матрицу в степень за $\O(\log k \cdot V^3)$.
Без доказательства: у этого процесса есть предел.
Можно либо взять большую константу и понадеяться на удачу, либо потенциально потерять в точности и решить систему уравнений на вероятности Гауссом.
Метод итераций: хотим решить $Ax=b$, переписываем как $(A+E)x-b=x$, взяли случайный вектор $x_0$, несколько раз заменили на $(A+E)x_0-b$.
Чтобы быстрее итерироваться, применили быстрое возведение в степень (добавили к $x$ лишнее значение, в котором всегда единица, чтобы получить матрицу).
