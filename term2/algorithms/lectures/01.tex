\chapter{Деревья поиска}
\setauthor{Елизавета Третьякова}
%<картинка про то, что слева и справа от х находятся элементы, строго меньшие и строг обольшие соответственно>
Сколько бывает деревьев поиска из элементов $0, 1, \ldots, n - 1$?
\[ K_{n} = \sum_{i = 0}^{n -1} K_{i} \cdot K_{n - i - 1} \]
(узнаём формулу чисел Каталана)

Хранить дерево будем структурой:
\begin{cppcode}
struct Node {
	Node *L, *R;
	int x;
	DataType Data;
};
\end{cppcode}

\begin{Rem}
	Если бы дерево было не бинарное, то мы бы сделали не \cpp'*L' и \cpp'*R',
	то есть левого и правого сыновей, а \cpp'*L' И \cpp'*Next' "--- 
	левого ребёнка  и правого соседа.
\end{Rem}

\begin{Rem}
	Ещё дерево можно хранить как \t{n}, \cpp'x[n]' и \cpp'parent[n]' "--- то есть 
	как вектор значений и родителей, доступ осуществляется по номеру вершины.
\end{Rem}

\begin{cppcode}
void insert(node* v, int x) {
	if(!v)
		return new Node(0, 0, x);
	 if(x < v->x)
		return new Node(insert(v->L, x), v->R, x);
	if(x > v->x)
		return new Node(v->L, insert(v->R, x), x);
	return v;
}
\end{cppcode}

\begin{Def}
	Персистентная структура данных (persistent data structure) "--- 
	структура данных, у которой в любой момент доступны все её версии 
	(от начальной и до текущей).
\end{Def}

\begin{cppcode}
Node* & find(Node* &v, int x) {
	if(!v)
		return v;
	if(v -> x == x)
		return v;
	return find(x < v-> x ? v -> L : v-> R, x);
}
\end{cppcode}

\begin{Rem}
	Другой способ сделать \t{Insert}: \cpp'find(Root, x) = new Node(0, 0, x);'
	Правда, тут стоило бы отдельно рассматривать случай возможного наличия $x$ в дереве.
\end{Rem}

\begin{Def}
	Поддерево "--- множество всех вершин, которые мы рекурсивно обошли, 
	выйдя из данной(которая тоже включается).
\end{Def}

Теперь мы хотим сохранить дерево в файл, причем так, чтобы его было удобно читать.
Пусть узлы нашего дерева описываются структурой
\begin{cppcode}
struct node* {
    node *L, *R;
    int x;
};
\end{cppcode}
Тогда функция сохранения в файл будет выглядеть следующим образом:
\begin{cppcode}
Save(node* v) {
    if(!v) {
        out(0); //out() "--- записать в файл четверку байт
        return;
    }
    out(v->x); //предположение: x != 0
    Save(v->L);
    Save(v->R);
}
\end{cppcode}
Функция чтения также рекурсивна.

Можно хранить (в файле) компактнее "--- не хранить ничего, кроме ключей. 
Порядок обхода при хранении делать прямым и понимать, что правое поддерево 
началось в тот момент, когда мы в первый раз встретили ключ, больший $x$.
Упражнение по этому поводу: сделать  это за $O(n)$.

\begin{Def}
	Порядок $xLR$ "--- прямой порядок обхода дерева.
	
	Порядок "\t{LxR}" "--- симметричный порядок обхода дерева.
\end{Def}

\begin{Rem}
	Если выписать элементы дерева в порядке симметричного обхода, 
	то мы получим отсортированный массив.
\end{Rem}

Еще три интересные нам функции "--- это \cpp'Left(node*)', \cpp'Right(node*)' и \cpp'Delete(node*&)'
(ей мы будем скармливать результат \t{find}"---а). 
\t{Left} и \t{Right} будут пока устроены обычным образом "--- 
пойти влево(вправо) один раз, а затем до упора вправо (влево, соответственно). 
И отдельно случай, когда у узла нет соответствующего поддерева.

\begin{cppcode}
Delete(node* &v) {
	if(!v->R)
		v = v->L;
	else {
		node* &t = Right(v);
		swap(v->x, t->x);
		t = t->R;
	}
}
\end{cppcode}

Также полезной функцией будет \t{DebugOuput}, который можно реализовать тремя основными способами:
\begin{enumerate}
\item
	Первый рекурсивный способ: мы выводим рекурсивно сначала левое поддерево в скобках,
	затем сам элемент, затем правое поддерево, также в скобочках и также рекурсивно.
	Получается примерно так:
	\[ (L) x (R) \]
\item
	Второй рекурсивный способ: выводить также в порядке прямого обхода, но вертикально,
	передавая в качестве параметра при рекурсивном вызове количество пробелов, 
	которое необходимо поставить перед очередным элементом 
	(это количество от уровня к уровню должно как-либо увеличиваться). 
	Псевдокод выглядит так:
\begin{cppcode}
Out(node* v, int depth) {
	Out(v->L, depth + 1);
	print(' ' * depth, x); //привет, Python? :)
	Out(v->R, depth + 1);
}
\end{cppcode}
\item 
	Способ вывести так, как мы дерево обыкновенно рисуем: завести двумерный буфер, 
	из размера левого сына получать размер отступа, в качестве параметра 
	передавать <<координаты>> точки, в которую надо писать.
\end{enumerate}

Теперь покажем, что наше дерево поиска хорошо работает. Заметим, что
\begin{description}
	\item[\t{Insert}:] $O(height)$
	\item[\t{Delete}:] $O(height)$
\end{description}

\begin{Def}
	Случайное дерево поиска "--- дерево поиска, полученное добавлением 
	случайной перестановки в пустое дерево.
\end{Def}

\begin{Def}
	Глубина случайного дерева равняется логарифму числа элементов.
\end{Def}
\begin{Def}
	Глубина вершины "--- расстояние от неё до корня.
\end{Def}
\begin{Def}
	Глубина дерева (<<высота>> в теорминах AVL-деревьев) "--- максимальная из всех глубин
	вершин этого дерева.
\end{Def}

\begin{theorem}{}
	Средняя глубина вершины случайного дерева равняется $O(\log n)$.
\end{theorem}
\begin{lemma}
	Сумма размеров поддеревьев равна сумме глубин по всем вершинам.
\end{lemma}
\begin{proof}
	\[ 
		\sum size_{i} = \sum_{b} |\{a \colon \text{$b$ "--- предок $a$}\}| = 
		\sum_{a} |\{b \colon \text{$b$ "--- предок $a$} \}| = \sum depth_{i} 
	\]
\end{proof}

\begin{lemma}
	У любого поддерева корень "--- случайная вершина из этого поддерева.
\end{lemma}
\begin{proof}
	Корень "--- это то, что мы добавили первым. Первый элемент случайной перестановки "--- это случайная величина.
\end{proof}

Мы хотим сделать наше дерево сбалансированным (как всегда, для скорости).
\t{Insert} будет работать за $\Omega(\log n)$, потому что 
мы можем за линию сделать симметричный обход и получить отсортированный массив, и 
если наш \t{Insert} работал быстрее, то мы могли бы сортировать 
любые данные быстрее, чем за $O(n \log n)$. 
Глубина BST (Balanced Search Tree) "--- $O(\log n)$. 
Операции \t{Find} и \t{Delete} можно сделать за $O(1)$ "--- для этого нужно, 
в первом случае, использовать hash table, а во втором не удалять элемент, 
а просто помечать удалённым.

Операции \t{Right} и \t{Left} можно сделать за амортизированное $O(1)$:
\[ T = \frac{\sum_{v = 1}^{n}Right(v)}{n} = O(1) \]
Но, когда очень хочется, можно сделать и так, чтобы $O(1)$ было в хужшем случае: для этого достаточно поддерживать ссылки на своих соседей \t{Right} и \t{Left} 
и пересчитывать их после \t{Insert} и \t{Delete}.
