\subsection{Граница Синглтона}
\begin{Def}
	$(n, k, d)$-код "--- линейный $(n, k)$-код с расстоянием $d$.
\end{Def}

\begin{theorem}
	В проверочной матрице кода нет $d-1$ линейно зависимых столбцов,
	но есть $d$ зависимых столбцов $\iff$ код имеет расстояние $d$.
\end{theorem}
\begin{Rem}
	Это позволяет проще искать расстояние линейного кода:
	не надо искать кодовое слово минимального веса.
	Но может быть проще.
\end{Rem}

\begin{theorem}[Граница Синглтона]
	Для любого \textit{линейного} кода:
	\[
	n - k \ge d - 1
	\]
\end{theorem}
\begin{proof}
	Рассмотрим проверочную матрицу $H$.
	Мы знаем, что расстояние кода "--- $d$,
	т.е. не существует кодового слова $c$ веса $\le d-1$ такого,
	что $cH^\top = 0$.
	То есть какие бы $d-1$ столбцов $H$ не взяли в линейную
	комбинацию, ноль не получим.
	То есть столбцовый ранг $H$ "--- хотя бы $d-1$.

	С другой стороны, в $H$ имеется $n-k$ строк,
	строковой ранг "--- не больше $n-k$,
	а строковой ранг совпадает со столбцовым даже в конечных полях.
\end{proof}
\begin{Rem}
	Если $n - k = d - 1$, то код \textit{лежит на границе Синглтона}
	или \textit{оптимален в смысле границы Синглтона}.
\end{Rem}
\begin{Rem}
	Например, коды Рида-Соломона лежат на границе Синглтона.
\end{Rem}

\subsection{Граница Варшамова-Гильберта}
\begin{theorem}[Граница Варшамова-Гильберта]
	Если $d \ge 3$ (этот тривиальный случай опускают в учебниках; надо рассматривать отдельно)
	и выполняется неравенство
	\[
		q^k \ge \frac{q^n}{V_{d-2}}
	\]
	то существует линейный $(n, k, d)$-код.

	Здесь $V_{d-2}$ "--- объём шара радиуса $d-2$:
	\[
		V_{d-2} = \sum_{i=0}^{d-2}\binom{n}{i}\cdot(q-1)^i
	\]
\end{theorem}
\begin{proof}
	Будем строить проверочную матрицу $H$ по столбцам слева направа.
	Первый столбец может быть какой угодно, но ненулевой.
	Второй столбец может быть какой угодно, но не кратный первому.
	Третий столбец может быть какой угодно, кроме линейной комбинации первых двух (возможно, тривиальной).
	И так далее: $j$-й столбец (нумерация с единицы) может быть какой угодно, кроме
	как равный линейной комбинации каких-то $\le d-2$ столбцов из уже выбранных
	(тогда его добавление не позволит получить линейно зависимый набор из $d-1$ векторов).

	Давайте оценим сверху количество таких линейных комбинаций:
	\[
	\binom{j-1}{0} \cdot (q-1)^0 +
	\binom{j-1}{1}\cdot(q-1)^1 +
	\binom{j-1}{2}\cdot(q-1)^2 +
	\dots +
	\underbrace{\binom{j-1}{d-2} \cdot (q-1)^{d-2}}_\text{нетривиальные линейные комбинации из $d-2$ векторов}
	\]
	Если это число строго меньше $q^r=q^{n-k}$, то мы можем выбрать очередной столбец.
	Мы хотим выбирать столбцы вплоть то столбца $j=n$, а столбец $j=n+1$ уже выбрать не получится,
	то есть будет верно противоположное неравенство:
	\[
	\binom{n+1-1}{0}\cdot(q-1)^0 +
	\binom{n+1-1}{1}\cdot(q-1)^1 +
	\dots +
	\binom{n+1-1}{d-2} \cdot (q-1)^{d-2}
	\ge
	q^{n-k}
	\]
	По счастливому совпадению, слева у нас в точности $V_{d-2}$:
	\begin{gather*}
		V_{d-2} \ge q^{n-k} \\
		q^k \ge \frac{q^{n-k}\cdot q^k}{V_{d-2}} = \frac{q^n}{V_{d-2}}
	\end{gather*}

	Осталось показать, что если это неравенство выполняется,
	то столбец $j=n$ в проверочной матрице мы всё-таки выбрать можем. \TODO
\end{proof}
\begin{Rem}
	Эта процедура построения в доказательстве называется \textit{процедурой Варшамова}
	(не гуглится, впрочем).
\end{Rem}
\begin{Rem}
	Формулировка <<если существут $(n, k, d)$-код, то неравенство>>, которая иногда есть, неаккуратна:
	Можно явно построить $(6, 3, 3)$-код в двоичном случае, но для него граница Варшамова-Гильберта не выполняется:
	\[
	2^3 < \frac{64}{1 + 6} \approx 9
	\]
\end{Rem}
\begin{Rem}
	А какая граница <<лучше>> "--- Гильберта или Варшамова?
	У Гильберта умеем строить код с:
	\[
	M \ge \frac{q^n}{V_{d-1}}
	\]
	У Варшамова умеем строить код с:
	\[
	M \ge \frac{q^n}{V_{d-2}}
	\]
	Итого получаем, что когда сузились от нелинейных кодов к линейным, то получили
	способ строить коды получше.
	То есть граница Гильберта была неточной.
\end{Rem}
\begin{Rem}
	Граница Варшамова-Гильберта тоже неточна: при $q \ge 49$ она улучшается.
	Нижние границы в принципе сложные и редко улучшаются.
\end{Rem}
\begin{Rem}
	Ещё надо аккуратно разобрать $d=1$ и $d=2$.
	Например, при $d=1$ у нас вообще не работает граница,
	а при $d=2$ у нас процедура Варшамова никогда не завершится, что неаккуратно.
\end{Rem}

\subsection{Коды Хэмминга}
Ещё разберём ещё несколько тривиальных случаев:
\begin{Def}
	\textit{Безизбыточные коды} "--- коды с $d=1$.
	Это $(n, n, 1)$ код, порождающая матрица "--- единичная, другого не бывате.
\end{Def}
\begin{Def}
	\textit{Проверка на чётность} "--- коды с $d=2$,
	где порождающая матрица "--- строчка из единиц.
	Это $(k+1, k, 2)$ код.
\end{Def}
\begin{Def}
	\textit{Коды с повторением} "--- коды с $d=n$, $k=1$.
	Тут порождающая матрица "--- это столбец из единиц.
	Просто повторили значение $d$ раз.
\end{Def}
\begin{Rem}
	Можно посмотреть на скорость, проверить границы, всё выполняется.
\end{Rem}
\begin{Rem}
	Коды с повторением \textit{дуальны} кодам с проверкой на чётность.
\end{Rem}

\begin{Def}
	\textit{Коды Хэмминга}:
	рассмотрим $q=2$ и проверочную матрицу размером $r \times 2^r-1$,
	у которой столбцы "--- все возможные ненулевые вектора из $r \ge 2$ бит.
\end{Def}
\begin{Rem}
	Ранг у неё $r$.
	Расстояние кода у неё будет хотя бы три, потому что никакие
	два столбца не являются линейно зависимыми.
	Но не четыре, потому что можно взять два столбца и их сумму.
	Итого построили конструктивно $(2^r-1, 2^r-1-r, 3)$-код.
\end{Rem}
\begin{Rem}
	Для $q>2$ тоже работает, но там надо аккуратно выкидывать коллинеарные вектора.
\end{Rem}
\begin{lemma}
	Коды Хэмминга совершенны "--- лежат на границе Хэмминга.
\end{lemma}
\begin{proof}
	\begin{gather*}
		M \le \frac{q^n}{V_t} \\
		2^k \le \frac{2^n}{V_1} \\
		2^{2^r-1-r} \le \frac{2^{2^r-1}}{1+n} \\
		2^{2^r-1-r} \le \frac{2^{2^r-1}}{1+2^r-1} \\
		2^{2^r-1-r} \le 2^{2^r-1-r}
	\end{gather*}
\end{proof}
\begin{Rem}
	Это важная конструкция: конструктивное построение нетривиального семейства совершенных по Хэммингу кодов.
	Есть конструкция вроде Рида-Соломона для кодов, лежащих на границе Синглтона.
\end{Rem}
\begin{Rem}
	Ещё на границе Хэмминга лежит всякая тривиальщина, двоичные и троичные коды Галлея.
	И всё, дальше было доказано, что ничего нет.
\end{Rem}

\subsection{Расширенные коды Хэмминга}
Берём $d=4$.

Возьмём проверочную матрицу кодов Хэмминга для $r$ и допишем к ней строчку и столбец
из нулей и единиц, чтобы добавить ещё один бит с проверкой чётности (работает и для $q>2$).
\begin{exmp}
	Пусть $q=2$, $r=3$, тогда дописываем вот так:
	\[
	H=\begin{pmatrix}
	0 & 0 & 0 & 1 & 1 & 1 & 1 & \textbf0 \\
	0 & 1 & 1 & 0 & 0 & 1 & 1 & \textbf0 \\
	1 & 0 & 1 & 0 & 1 & 0 & 1 & \textbf0 \\
	\textbf1 & \textbf1 & \textbf1 & \textbf1 & \textbf1 & \textbf1 & \textbf1 & \textbf1
	\end{pmatrix}
	\]
\end{exmp}
Получаем длину кода $2^r$, увеличилась на единицу.
Высота матрицы тоже увеличилась на единицу до $r+1$.
Количество информационных символов осталось прежним "--- $2^r-1-r$, количество проверочных увеличилось.

Посмотрим, что произошло с расстоянием.
Оно всё ещё как минимум три: все столбцы непропорциональны,
любые два старых остались линейно независимы по верхней части,
новый линейно независим со всеми старыми.

На самом деле оно стало хотя бы четырём: рассмотрим произвольные три столбца.
Если они все из старой половины, то есть линейная независимость в нижней строчке.
А если один из новой, то два в старой линейно независимы по верхней части.

При этом оно не больше четырёх: берём из старой матрицы три линейно зависимых столбца,
добавляем новый, получаем четыре линейно зависимых столбца.

\begin{Def}
	Таким образом получили $(2^r, 2^r-r, 4)$-код "--- это \textit{расширенный код Хэмминга}.
\end{Def}
\begin{Rem}
	Он всё ещё исправляет одну ошибку, но теперь может обнаружить две ошибки вместо одной.
\end{Rem}
\begin{Rem}
	Этот код уже совершенным не является.
\end{Rem}
\begin{Rem}
	Эта техника обобщается: мы можем повысить расстояние с нечётного до чётного.
	С чётного повысить не получится.
\end{Rem}

\section{Декодирование линейных кодов}
Мы уже умели:
\begin{itemize}
\item Перебирать вообще все кодовые слова и искать ближайшее
\item Искать ближайшее кодовое слово в шаре
\item Предподсчитать решающие области
\end{itemize}

\begin{Def}
	\textit{Синдром} вектора $b$ "--- это $s(b)\coloneqq bH^\top$.
\end{Def}
\begin{lemma}
	Если у нас принят вектор $b=c+e$ (где $c$ "--- исходное кодовое слово, а $e$ "--- ошибка),
	то $s(b)=s(e)$:
	\[
		s(b) = s(c + e) = (c + e)H^\top = cH^\top + eH^\top = eH^\top = s(e)
	\]
\end{lemma}
\begin{Rem}
	Вырисовывается алгоритм декодирования: один раз заранее предподсчитать
	табличку $e \to s(e)$, а потом научиться по $s(e)$ искать ошибку и исправлять.
\end{Rem}
\begin{Rem}
	Какие конкретно $e$ брать, чтобы синдромы не совпадали и что вообще делать
	при неоднозначностях "--- чуть попозже.
\end{Rem}
