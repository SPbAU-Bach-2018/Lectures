\chapter{Занятие 25.03.2016}
\section{Разбор задач}

\subproblem{22}{h}
	Разбирал Дима Розплохас.

	Идея немного похожа на \hyperref[prob22g]{решение задачи 22g}.
	Давайте заметим, что слово лежит в языке $\iff$ оно имеет следующий вид (с точностью до замены \t{a} и \t{b}),
	где $\alpha$ "--- произвольная буква:
	\[
		\overbrace{\somealpha{i}\t{a}\somealpha{k}}^x \overbrace{\somealpha{i}\t{b}\somealpha{k}}^x
	\]
	То есть слово состоит из двух половинок одинаковой длины $i+k+1$, у которых на позиции $i+1$ стоят разные буквы.
	При этом оставшиеся части могут быть произвольны.
	Немного перепишем:
	\begin{gather*}
		\somealpha{i}\t{a}\somealpha{k}\somealpha{i}\t{b}\somealpha{k} \\
		\somealpha{i}\t{a}\somealpha{k+i}\t{b}\somealpha{k} \\
		\somealpha{i}\t{a}\somealpha{i+k}\t{b}\somealpha{k} \\
		\overbrace{\somealpha{i}\t{a}\somealpha{i}}^{A}\overbrace{\somealpha{k}\t{b}\somealpha{k}}^{B}
	\end{gather*}
	Последнюю конструкцию уже легко записать в виде контекстно-свободной грамматики: каждое из $A$ и $B$
	записывается, а дальше $L$ является простой конкатенацией их в некотором порядке.
	Получаем такую грамматику:
	\begin{align*}
		X &\to \t{a} \mid \t{b} \\
		A &\to \t{a} \mid X\,A\,X \\
		B &\to \t{b} \mid X\,B\,X \\
		S &\to A\,B \mid B\,A
	\end{align*}

\problem{21}
	Разбирал Никита Подгузов.
	\TODO

	\begin{Rem}
		Замечание от семинариста: а зачем вообще нужна эта задача?
		Она позволяет доказать теорему Клини еще одним способом.
		Пусть у нас есть автомат из $k$ состояний, а мы хотим построить регулярное выражение.
		Давайте рассмотрим систему уравнений на языки $L_1, \dots, L_k$ (где $L_i$ "--- язык,
		принимаемый автоматом, если начинать из состояния $i$).
		Уравнение на $L_i$ легко составить: для каждого перехода по букве \t{c} в состояние $L_j$
		добавляем к $L_i$ язык $\t{c}L_j$.
		Если переход терминальный, то еще добавляем строку $\epsilon$.

		Теперь будем потихоньку подставлять один язык в другой: сначала подставляем $L_1$ во все остальные,
		потом $L_2$ во все следующие, и так далее.
		В конце получим одно уравнение на $L_k$.
		\TODO дальше надо применить задачу и разворачивать обратно
	\end{Rem}

\problem{23}
	Разбирала Надежда Бугакова.

	Давайте строить КС-грамматику для нового языка $A/B$.
	Будем считать, что язык $A$ был задан в нормальной форме Хомского,
	а в автомате для языка $B$ ровно одно начальное состояние и ровно одно терминальное.
	\begin{Rem}
		При таком допущении автомат для языка $B$ становится недетерминированным: самый простой способ
		сделать ровно одно терминальное "--- добавить новое фиктивное состояние и провести в него $\epsilon$-переходы из всех старых терминальных.
		Более того, детерминизировать получившийся автомат бессмысленно "--- после детерминизации у нас опять потенциально может оказаться много терминальных состояний.

		Нам в этом решении недетерминированность нестрашна.
	\end{Rem}
	Давайте мы для каждого нетерминала $X$ старой грамматики введём целую серию нетерминалов в грамматике $A/B$.
	Будем их называть $X_{sf}$, где $s$ и $f$ "--- два произвольные состояния автомата для языка $B$.
	Инвариант такой: $X_{sf}\xLongrightarrow{*} w$ (тут $w$ "--- строка) тогда и только тогда,
	когда $X \xLongrightarrow{*} w$ и, более того, если скормить некоторый суффикс слова $w$ автомату,
	начиная из состояния $s$, то автомат может закончить в состоянии $f$.

	Здесь мы пользуемся задачей 24, чтобы построить грамматики для таких нетерминалов: нетерминал $X$ задаёт некоторый
	контекстно-свободный язык, а требование про автомат задаёт некоторый регулярный язык: легко построить
	требуемый для него автомат (просто возьмём исходный, разрешим ему вначале пропустить сколько-то символов,
	а дальше он должен начать из $s$ и закончить в $f$).

	Таким образом, построили все возможные нетерминалы $X_{sf}$ (возможно, какие-то из них соответствуют пустым языкам,
	возможно, их потребуется выкинуть, если совсем-совсем аккуратно делать).
	Нетерминал $S_{s_0t_0}$ (тут $S$ "--- стартовый нетерминал исходной, $s_0$ и $t_0$ "--- начальное и конечное состояния автомата)
	объявим стартовым нетерминалом грамматики "--- это в точности соответствуют условию задачи: все строки, выводимые из $S$,
	некоторый суффикс который лежит в $B$.

	\begin{Rem}
		Нормальная форма Хомского не потребовалась.
		Но мы могли бы и честно расписать построение грамматики для $X_{sf}$ "--- и вот тут форма Хомского бы упростила рассуждения.
	\end{Rem}

\problem{24}
	Разбирал Дима Лапшин.

	Берём описание КС-языка в виде грамматики и детерминированный автомат для регулярного языка.
	Аналогично предыдущей задачи возьмём каждый нетерминал $A$ и в новом языке создадим
	нетерминалы $A_{pq}$ "--- все слова, в которые разворачивался $A$, переводящие автомат
	из состояния $p$ в состояние $q$.

	Преобразования правил происходит так: если было правило $A \to X_1X_2X_3\dots X_k$, то для $A_{pq}$ можно выписать множество правил.
	Надо просто смотреть, как может меняться состояние автомата по ходу разворачивания $X_i$:
	\begin{itemize}
		\item
			Если какое-то $X_i$ является буквой, то состояние меняется однозначно.
		\item
			Если $X_i$ является нетерминалом, то надо перебрать, в какое именно состояние $X_i$ переведёт автомат из текущего.
	\end{itemize}
	Если же не получилось ни одного перехода из $A_{pq}$, то его надо вообще убить.
	В конце скажем, что начальным состоянием является объединение $A_{st}$, где $s$ "--- начальное, а $t$ "--- все терминальные.

	\begin{Rem}
		В нормальной форме Хомского рассказывать было бы проще.
	\end{Rem}

\problem{27}[неверное]\label{prob27_wrong}
	Разбирал Сева Степанов и завалился.

	Пусть у нас есть строчка из терминалов и нетерминалов.
	Назовём \textit{маской} множество нетерминалов, встречающихся в строчке,
	всего различных масок $2^b$.
	Значит, по принципу Дирихле, в процессе вывода у нас было две строчки $s_1$ и $s_2$ с одинаковыми масками.
	Дальше захотелось сказать, что тогда у нас $|s_2|>|s_1|$ и можно еще раз повторить
	те же правила вывода (что были между $s_1$ и $s_2$) и раздувать строку до бесконечности, получив бесконечный язык.
	Но, увы, это в таком виде неправда: если $s_1=A\,A\,B$ и $s_2=\t{a}\,A\,B$, то маски одинаковые (равны $\{A, B\}$),
	но никакого <<раздувания>> тут не произошло.

\problem{27}[верное]\label{prob27}
	Разбрала Надя Бугакова.

	От противного.
	Предположим, что язык конечный.
	Будем доказывать индукцией по количеству нетерминалов в грамматике ($b$), что в любом выводе конечного языка
	(если его грамматика записана в нормальной форме Хомского) размер вывода строго меньше $2^b$ (т.е. не более $2^b-1$).

	База: пусть у нас всего один нетерминал, тогда может быть лишь вывод $S\to \alpha$,
	а вывода $S \to SS$ быть не может (иначе язык бесконечный).
	Таким образом, есть один нетерминал и один вывод (что строго меньше $2^1=2$).

	Переход: пусть у нас в грамматике есть переход $S \to AB$.
	Тогда заметим, что как бы ни разворачивались нетерминалы $A$ или $B$, нетерминал $S$ в процессе возникнуть не может,
	иначе язык бы получился бесконечным: этот нетерминал $S$ можно разворачивать рекурсивно в сколь угодно длинную строку.
	\begin{Rem}
		Тут мы воспользовались тем, что в нормальной форме Хомского никакой нетерминал не может перейти в пустую строчку,
		и, как следствие, если в процессе разворачивания нетерминала получился он же, то мы по дороге нарастили строчку.
	\end{Rem}
	Теперь давайте выкинем нетерминал $S$ из нашего языка.
	Рассмотрим два получившихся языка: один начинается в нетерминале $A$, другой "--- в $B$, оба конечны,
	для каждого из них осталась грамматика в нормальной форме Хомского.
	Применяем для каждого из них индукционное предположение: получаем, что из первого мы получили строчку не более, чем за $2^{b-1}-1$ выводов, аналогично для второго.
	Складываем, получаем, что после разворачивания $S$ в $AB$ нам требуется не более $2(2^{b-1}-1)=2^b-2$ выводов/
	Добавляем один неучтённый вывод ($S \to AB$), получаем ровно $2^b-1$, что и требовалось доказать.

\problem{26}[от Димы]
	Разбирал Дима Розплохас.

	Давайте построим грамматику для $C$ в нормальной форме Хомского, получим $n$ нетерминалов.
	Так как он бесконечный, то в нём, в частности, есть слова длины хотя бы $2^{100n}+100$, возьмём одно такое слово.
	Посмотрим на дерево разбора этого слова.
	Если у нас все ветки длины (в вершинах) не больше $n$, то всего веток не больше $2^{n-1}$, а
	суммарное число вершин не более $n2^{n-1}$, что не позволит получить такое длинное слово.
	Значит, есть длинные ветки.
	Возьмём какую-нибудь такую ветку, в ней какой-то терминал $T$ встречается хотя бы два раза.
	Пройдём по ветке до первого $T$, получим вывод из $S$ некоторой строки $\alpha T \bar\alpha$.
	Потом "--- от первого $T$ вниз до второго $T$, получим вывод из $T$ строки $\beta T \bar\beta$,
	при этом $|\beta| + |\bar\beta| > 0$ (потому что нормальная форма Хомского).
	Потом "--- от второго $T$ вниз до строки, получим вывод из $T$ строки $\gamma$.

	Таким образом, получаем, что все слова вида $\alpha \beta^k \gamma \left(\bar\beta\right)^k \bar\alpha$ принадлежат нашему языку.
	Два случая:
	\begin{itemize}
		\item Если $\beta \neq \epsilon$, то можно взять регулярный язык $\alpha\beta^*\gamma$ "--- все его слова являются префиксами исходного языка $\Ra$ лежат в нём по условию задачи.
		\item Если $\beta = \epsilon$, то получаем регулярный язык вообще нахаляву: $\alpha \beta^k \gamma \left(\bar\beta\right)^k \bar\alpha = \alpha \gamma \left(\bar\beta\right)^k \bar \alpha$
	\end{itemize}

	\begin{Rem}
		От семинариста: можно доделать до обобщённой леммы о накачке.
		Если есть бесконечный язык, то в нём можно найти сколь угодно длинное слово такое,
		что его можно разбить на пять частей: $xuywz$, причём все слова вида
		$xu^iyw^iz$ тоже лежат в языке.

		Так можно доказывать неконтекстно-свободность каких-то языков.
	\end{Rem}

\problem{26}[от Оли]
	Разбирала Оля Черникова.

	Опять построим грамматику в нормальной форме Хомского.
	Попробуем найти ответ вида $\alpha\beta^*$.

	Давайте посмотрим на нетерминал $S$.
	Так как он порождает бесконечный язык, то есть какой-то переход $S \to AB$,
	где либо $A$, либо $B$ тоже порождает бесконечный язык.
	Если $A$ порождает бесконечный язык, то пойдём в $A$.
	Если нет, то пойдём в $B$, выписав какое-нибудь слово из $A$.
	Так будем идти-идти-идти и в какой-то момент зациклимся, прийдя в тот нетерминал, в котором уже были (назовём его $T$).

	С начала работы мы выписали длинную строку из слов, из них какие-то шли до первого $T$ "--- объединим их и назовём $\alpha$.
	А какие-то шли от первого $T$ до второго "--- их объединение назовём $\beta$.
	Тогда все слова слова $\alpha\beta^*$ лежат в языке.
	\begin{Rem}
		Тут мы опять воспользовались тем, что в нормальной форме Хомского $\beta$ непусто,
		так как при выводе нетерминалов из нетерминала длина результата строго увеличивается.
	\end{Rem}

\problem{29}
	Разбирал Никита Подгузов.

	Распилим строку на две: $s$ и $t$:
	\[
		\underbrace{\t{c}^m \t{a}^{l_0} \t{b} \dots \t{a}^{l_{m-1}} \t{b}}_{s} \underbrace{\t{a}^{l_m}\t{b} \dots \t{a}^{l_z} \t{b} \t{d}^n}_{t}
	\]

	Заметим, что такое разбиение однозначно: в начале строки идёт определённое количество букв \t{c},
	по которому можно определить, сколько дальше идёт групп $\t{a}^x\t{b}$ до границы слов $s$ и $t$.
	Тогда построим однозначные грамматики для всех слов $s$ и всех слов $t$, допишем одно к другому,
	получим однозначную грамматику для исходного языка.

	Разбираемся с $s$.
	При $m=0$ строка $s$ является пустой, при увеличении $m$ слева дописывается \t{c}, справа "--- $\t{a}^*\t{b}$.
	$\t{a}^*\t{b}$ умеем выражать однозначной грамматикой, получили однозначную грамматику для $s$:
	\begin{align*}
		X &\to \t{b} \mid \t{a}\,X \\
		S &\to \epsilon \mid \t{c}\,S\,X
	\end{align*}

	Разбираемся с $t$.
	При $n=0$ слово $t$ есть группа из $\t{a}^0$ (т.е. пустой строки), потом сколько-то групп $\t{b}\t{a}^*$, потом завершающая \t{b}.
	При увеличении $n$ слева дописываем $a$, справа дописываем $d$, тоже всё однозначно (надо только аккуратно описать
	звезду Клини):
	\begin{align*}
		Y &\to \t{b} \mid Y\,\t{a} \\
		Y' &\to \epsilon \mid Y\,Y' \\
		T &\to Y'\,\t{b} \mid a\,T\,d
	\end{align*}

	\begin{Rem}
		На самом деле, не все грамматики переделываются в однозначные.
		Есть инструменты, позволяющие показывать, что грамматика неоднозначна.
		Они похожи на инструменты, показывающие, что грамматика не является контекстно-свободной.
	\end{Rem}

\section{Подсказки}
\subproblem{15}{c}[подсказка]
	Идея такая: если у нас у МТ мало памяти, то состояний очень мало.
	$\log \log$ каким-то образом вылезает из \hyperref[prob15a]{задачи 15а}.
	\TODO
%	там какая-то формула $2^ccq$, а потом еще раз в
%	формуле $(2^ccq)^{2^ccq}$.

\problem{28}[подсказка]
	Алфавит размера 2 "--- это \textbf{очень} важно.
