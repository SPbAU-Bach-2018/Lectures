\section{Вероятностные алгоритмы}
Вероятностный алгоритм --- это алгоритм, который может использовать 
случайные числа. Случайные числа со входом никак не свзяны и у алгоритма есть 
отдельный источник.

Источник выдает равновероятно 0 и 1, хотя, в целом, можно использовать и
не равновероятные варианты, но мы этим заниматься не будем.

Случайные биты можно понимать как дополнительную ленту Машины Тьюринга 
или как подсказку.   

Алгоритмы бывают с одностороней ошибкой, двустороней ошибкой 
и без ошибки вовсе. Если алгоритм работает без ошибки, это 
значит, что случайные биты только помогают сэкономить время. 
Одностороняя ошибка, это когда один ответ дается с полной ясностью, 
а второй ответ можеть быть не верным. 


Сделаем определение класса $RP$ из определения класса $NP$.
\begin{Def}
$L \in NP$, если имеется п.о. п.п R, такая, что $\forall x \in \{0, 1\}^*$\\
\begin{enumerate}
\item $x \not \in L \Ra \forall w (x, w) \not \in R$
\item $x \in L \Ra \exists w (x, w) \in R$
\end{enumerate}
\end{Def}

Класс RP отличается тем, что он требует, что бы 
хороших ответов было много. 

\begin{Def}
$L \in RP$, если имеется п.о. п.п R, такая, что $\forall x \in \{0, 1\}^*$\\
\begin{enumerate}
\item $x \not \in L \Ra \forall w (x, w) \not \in R$
\item $x \in L \Ra \frac{|\{w |(x, w) \in R\}|}{\{\text{всех }w\}} > \frac{1}{2}$
\end{enumerate}
\end{Def}

В целом, мы всегда можем уменьшить вероятность ошибки. 
Если мы ошибались с вероятносью $\frac{1}{2}$, то запустим алгоритм $k$
раз и вероятность ошибки уже будет $\frac{1}{2^k}$. То есть, если все запуски 
алгоритма вернули 0, то выдать 0, а если хоть какой-то алгоритм выдал 1, то 
сразу с увереностью выдать 1. 

На самом деле любой вероятностный алгоритм легко сделать с ошибкой с совсем 
маленкой вероятностью. 

\begin{Def}
$L \in BPP$,  если п.о п.п $R$, такая, что $\forall x \in \{0, 1\}^*$
\begin{enumerate}
\item 
$x \not \in L \Ra \frac{|\{w |(x, w) \in R\}|}{\{\text{всех }w\}} < \frac{1}{3}$
\item 
$x \in L \Ra \frac{|\{w |(x, w) \in R\}|}{\{\text{всех }w\}} > \frac{2}{3}$
\end{enumerate}
\end{Def}
$\frac{1}{3}$ и $\frac{2}{3}$ это произвольные константы. Можем взять 
любые две отличимые. Здесь уменьшить вероятность ошибку чуть-чуть сложнее. 

Повтрим алгоритм много раз. Он нам выдаст кучу разных ответов, 
нужно взять по большинству и это выдать. И что бы понять, с какой 
вероятностью большинство будет неправильным нам потребуется неравенство 
Чернова. 


Случаная величина в данном случае это вероятность выдать правильный ответ. 
После k запусков матожидание правильных ответов $\frac{2}{3}k$. Нас интересует 
вероятность того, что количетсво неправльных ответов 
окажется больше половины. 

\begin{Def}
Неравенство Чернова
 
$Pr{X > (1 + \epsilon)pk} < (\frac{e^{\epsilon}}{(1 + \epsilon)^{1 + \epsilon}})^{pk} \le e^{-\frac{pk\epsilon^2}{4}}$

Где $X = \sum_{i = 1}^{k}x_i$, а $x_i$ --- независимые случайные 
велечины, принимающие 1 с вероятностью $p$ и 0 c вероятностью $(1 - p)$.
\end{Def}

$Pr\{\text{ошибок более} \frac{k}{2}\} \le 2^{- \omega(k)}$\\

Теперь в определения мы можем поставить сколь угодно малую константу и  1- 
сколь угодно малую константу. 

Так же, мы можем сделать еще лучше, и запустить алгоритм полином раз.

Теперь определим бесполезный класс. 
\begin{Def}
$L \in PP$, если имеется п.о. п.п. $R$, такая, что $\forall x \in \{0, 1\}^*$ \\
\item 
   $x \not \in L \Ra \frac{|\{w |(x, w) \in R\}|}{\{\text{всех }w\}} < \frac{1}{2}$
\item 
   $x \in L \Ra \frac{|\{w |(x, w) \in R\}|}{\{\text{всех }w\}} > \frac{1}{2}$
\end{Def} 

Здесь мы уже не можем уменьшить вероятность ошибки.


\begin{exmp} 
Приведем пример задачи, которую мы не умеем быстро решать 
за полином детерминировано, зато хорошо умеем решать вероятностно. 

А именно. Дан многочлен, нужно проверить, что он нулевой. 

Для этого нам достатчно подставить в многочлен от $n$ переменных $n$ точек, 
с хорошей вероятностью результат будет не нулевой. 

\begin{lemma} Sehwartr-Zippel\\
$S \subset F, \deg Q \le d$\\
$\Pr\{Q(r_1, \cdots, r_n) = 0\} \le \frac{d}{|S|}$\\
$r_1, \cdots, r_n \in S$\\
\end{lemma}
\begin{proof}
Докажем по индукции по числу переменных:

По предположению многочлен не нулевой. 
$Q(x_1, \cdots, x_n) = x_1^kq_k(x_2,\cdots, x_n) + x_1^{k - 1}q_{k - 1}(x_2, \cdots, x_n) + \cdots + q_0(x_2, \cdots, x_n)$\\
С какой вероятностью здесь написан не ноль? Что бы это был не нуль, нужно, что бы $q_k(x_2, \cdots, x_n)$ не был равен нулю. 
Он не ноль с вероятностью $\le \frac{d - k}{|S|}$. Теперь, мы получили многочлен от одной переменной. Подставили что-то в нее. 
Многочлен станет ноль с вероятностью $\frac{k}{|S|}$. Что бы был ноль, нужно что бы случилось хоты бы одно из этих двух событий, 
тогда итоговая вероятность $\frac{n}{|S|}$.
\end{proof}
\end{exmp}

Эту лемму надо запомнить надолго, она у нас еще появится.

Здесь должна быть красивая картинка с тем, как классы вкаладываются друг в друга. 

RP частный случай NP, поэтому RP живет в NP.
\begin{theorem}
$BPP \subset P/poly$\\
\end{theorem}
\begin{proof}
В BPP много хороших подсказок. 

Что бы доказать, что язык принадлежит $P/poly$, нам достаточно для всех языков 
данной длины выбрать одну хорошую подсказку и зашить ее в схему.

Для каждого входо негодных подсказок $\frac{1}{2^{poly}} $. Возьмем в качестве этого poly просто 2n, 
тогда для каждого входа плохих подсказок $\frac{1}{4^n}$. При этом всего входов данной длины $2^n$. Значит 
суммарно плохих подсказок, которые хоть где-то врут, меньше, чем $\frac{1}{4^n}2^n << 1$.

Значит куча подсказок являются годными для всех. Эту подсказку мы и возьмем и зашъем в схему.
\end{proof}

\begin {theorem}
$BPP \subset \Sigma_2 \cap \Pi_2$\\
\end{theorem}
\begin{proof}
Класс BPP замкнут относительно дополнения, поэтому, если BPP лежит в $\Sigma_2$, 
то он сразу лежит и в $\Pi_2$.

Давай-те рисовать формулу с двумя кванторами для языка из $BPP$. Мы опять будем каким-нибудь образом 
открывать множество всех подсказок, но чуть подругому. 

Хотим показать, что множество подсказок, которые приводят к ответу 1 велико, не правильному, а один, если это так, 
то мы знаем из определения, что правильный ответ 1. Что бы показать, 
что оно велико, то мы наделаем его копии и покажем, что мы смогли покрыть все множество подсказок. Умерино размножить,  множетсво подсказок. 

Размножать мы будем с помощью xor.

Возьмем какую-нибудь строчку $t_i$ и ее приксоим к каждой строчке-подсказке, тем самым
мы получим новое множество подсказок.

Вот такими копиями мы хотим покрыть все пространство подсказок.
$r \in A_x \oplus t_i \Lra R(x, r \oplus t_i) = 1$ \\
$r \not \in A_x \oplus t_i \Lra R(x, r \oplus t_i) = 0$\\

$\exists\{t_i\}_{i = 1}^{k} \forall r \in U \vee_{i = 1}^{k}(r \in A_x \oplus t_i)$ \\

Надо теперь как-то понять, что вот именно такие копии нам подойдет.

Возьмем $t_i$ случайным образом и посчитаем вероятность неприятности.
$Pr(\exists r\in U \wedge_{i = 1}^{k}(r \not \in A_x \oplus t_i)) \le$\\
$\sum_{r \in U}Pr(\wedge_{i = 1}^{k}r \not \in A_x \oplus t_i) = \sum_{r \in U} \prod_{i = 1}^{k}Pr\{r \not \in A_x \oplus t_i\}$\\
$\le \frac{1}{2^{nk}}2^{p(n)}$ 
\end{proof}

\begin{Def}
$ZPP = RP \cap co-RP$ \\
\end{Def}
Теперь, почему это нулевая вероятность ошибки. 
В данном случае получается, что у нас язык такой, что для него есть 
два алгоритма. Из $RP$ и $co-RP$. Алгоритм из $RP$ нам точно отвечает для 
слов не из языка. А $co-RP$ ошибается, но в другую сторону. Соответственно, 
нужно запустить оба алгоритма. Если алгоритм из $RP$ сказал 1, то все, значит точно 
1, а если алгоритм из $co-RP$ дал 0, значит точно ноль. Соответственно, 
нужно подождать, пока один из них не даст ответ, в котором он уверен. 

Как же долго будет происходить этот процесс? Теоретически, он может, 
конечно, вечно работать. Но можем оценить матожидание времени работы. 

Матожидание количества запусков, соответственно, константа.
$\frac{1}{2}\cdot 1 + \frac{1}{4}\cdot 2 + \frac{1}{8}\cdot3 + \cdots$

Теперь наоборот, пусть у нас есть алгоритм, матожидание времени работы которого
полиномиально, тогда мы хотим убедиться, что есть два алгоритма, один из 
RP, другой из $co-RP$.

Запускаем наш алгоритм и ждем, когда он отработает и ставим будильник. 
Даем ему работать время $k Et$. Ошибиться он может только, если не успел 
отработать. Вероятность этого мы можем оценить с помощью неравенства Маркова. 

\section{Интерактивные доказательства}
У нас будут интерактивные протоколы такого рода. У нас будет Prover и Verifier. 
Prover будет что-то там доказывать, а Verifier будет проверять. Иногда
их называют Mерлин и Артур. 

Они оба видят вход. Prover всесильный, он может даже вычислять не вычислимые задачи, а 
verifier он скромный, он ограничен полиномиальным временем и он использует случайные числа. 

Случайные числа могут быть секретные, а могут быть публичные. Секретные, это те, которые 
prover не видет. А публичные видят оба. Соответственно public coin(MA), private coin(PV).

Проводится сколько-то раундов $MAM$, $AM$... 

В конце раундов A должен сказать правда это или нет. И мы хотим, что бы 
он говорил, что эта правда с достаточно хорошей вероятностью. 

\begin{Def}
Язык $L \in MA$, если имеются такие полиномы p и q и 
полиномиальная ДМТ A, что $\forall x \in \{0, 1\}^*$\\
\begin{enumerate}
\item $x \in L \Ra \exists y \in \{0, 1\}^{p|x|} \colon Pr_{Z \in \{0, 1\}^{q(|x|)}} \{A(x, y, z) = 1\} > \frac{3}{4}$ \\
\item  $x \not \in L \Ra \forall y \in \{0, 1\}^{p|x|} \colon Pr_{Z \in \{0, 1\}^{q(|x|)}} \{A(x, y, z) < \frac{1}{4}\} = 1$ \\

\end{enumerate}

\end{Def}

\begin{Def}
Язык $L \in AM$, если имеются такие полиномы p и q и 
полиномиальная ДМТ A, что $\forall x \in \{0, 1\}^*$\\
\begin{enumerate}
\item $x \in L \Ra Pr_{Z \in \{0, 1\}^{q(|x|)}} \{\exists y \in \{0, 1\}^{p|x|} \colon  \{A(x, y, z) = 1\} > \frac{3}{4}$ \\
\item $x \in L \Ra Pr_{Z \in \{0, 1\}^{q(|x|)}} \{\exists y \in \{0, 1\}^{p|x|} \colon  \{A(x, y, z) = 1\} < \frac{1}{4}$ \\
\end{enumerate}

\end{Def}

\begin{exmp}
Неизоморфизм графов.

Мерлин доказывает, что $G_0 \not \sim G_1$.

Артур берет или первый либо второй и применяет к нему 
случаную перестановку. Если эти два графа неизоморфны, 
то Мерлин правильно ответит, он всесильный. 

А теперь, если изоморфны, и он не может их 
различить и угадает ответ с вероятностью $\frac{1}{2}$. 
\end{exmp}

\begin{Def}
Язык $L \in IP$, если имеются prover(функция) P и verifier 
(полиномиальная вероятностная МТ)V, такая, что $\forall x \in \{0, 1\}^{*}$\\
\begin{enumerate}
\item 
$x \in L \Ra Pr\{V^{P}(x) = 1\} = 1$\\
\item 
$x \not \in L \Ra \forall P' Pr\{V^{P'}(x) = 1\} < \frac{1}{4}$\\
\item 
\end{enumerate}
\end{Def}


Правда жизни состоит в том, что если у нас константное число 
раундов, то мы всегда можем сократить их до 
двух, но в порядке сначала Арутур, потом Мерлин. И добавив два лишних
раунда можем избавится от приватности случайных чисел. 

$NP \subset MA \subset AM$. Они чуть-чуть выше $NP$.

Если обменов не константа, а полином, то мы сразу получаем $PSPACE$.