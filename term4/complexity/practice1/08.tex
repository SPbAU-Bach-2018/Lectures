\chapter{Занятие 30.03.2016}

\section{Вопросы}
\subsection{Определения $\MA$ и $\AM$}
	Мерлин умеет вычислять любые
	функции от известной ему информации, Артур "--- только полиномиальные.
	Мерлин хотит убедить Артура, что некоторая строка $x$ лежит в $L$, а Артур боится, что его обманут.

	Вот у нас есть строка фиксированной длины из букв $M$ и $A$ "--- название класса.
	Она описывает последовательность ходов.
	Когда ходит Артур, он генерирует сколько-то случайных бит и посылает их Мерлину.
	Когда ходит Мерлин, он посылает Артуру какую-то строчку из бит.
	После всех раундов Артур должен за \textit{полиномиальное от $|x|$} время принять решение, верит он Мерлину или нет.
	Соответственно, отсюда сразу следует, что количество переденных бит (суммарно в две стороны)
	тоже полиномиально от входа.
	
	Тут Артур ничего Мерлину не посылает (кроме случайных бит), но это и
	неважно "--- Мерлин и так может посчитать, что бы Артур хотел ему послать.

	\begin{Def}
		Определим класс $\MA$.
		Язык $L$ принадлежит $\MA$ если и только если есть такая полиномиальная
		детерминированная машина $A$, что выполняются два факта:
		\begin{gather*}
			x \in    L \iff \exists z \colon \Pr_r[ A(x, r, z) = 1 ] \ge \frac 3 4 = \epsilon_1 \\
			x \notin L \iff \forall z \colon \Pr_r[ A(x, r, z) = 1 ] <   \frac 1 4 = \epsilon_2
		\end{gather*}
		Смысл такой: сначала Мерлин присылает сообщение $z$, потом Артур выбирает случайные биты $r$
		и в конце алгоритмом $A$ решает, верить Мерлину или нет.
		Первое неравенство обозначает, что у Мерлина есть стратегия, позволяющая убедить Артура в том,
		что слово лежит в языке, с довольно хорошей вероятностью.
		Вторая строчка обозначает, что если $x \notin L$, то Мерлин никакой стратегией не сможет нас
		с хорошей вероятностью убедить, что слово в языке.
	\end{Def}
	\begin{Rem}
		Нам в определении важно, что $|\epsilon_1 - \epsilon_2| \ge \frac{1}{Poly(n)}$,
		иначе Артур будет вести себя абсолютно одинаково и если слово в языке, и если не в языке.
		Никак не отличим.
		А если вероятности различаются на полином, ты за полиномиальное число запусков протокола
		мы можем понять, на что больше похоже количество выданных единиц "--- на $\epsilon_1$ или на $\epsilon_2$.
	\end{Rem}
	\begin{Rem}
		Надо сказать, что у нас в определении никак не оговорено, что происходит, если Мерлин выбирает
		неправильную стратегию убеждать нас в том, что слово принадлежит языку (т.е. выбирает неправильное $z$).
		Поэтому сейчас машина Артура может выдавать что угодно.
		Потом, возможно, мы это как-то изменим.
	\end{Rem}

	\begin{Def}
		Язык $L$ принадлежит $\AM$ если и только если есть такая полиномиальная
		детерминированная машина $A$, что выполняются два факта:
		\begin{gather*}
			x \in    L \iff \colon \Pr_r[ \exists z \colon A(x, r, z) = 1 ] \ge \frac 3 4 \\
			x \notin L \iff \colon \Pr_r[ \exists z \colon A(x, r, z) = 1 ] < \frac 1 4
		\end{gather*}
		Тут сначала Артуром выбираются случайные биты $r$, а уже потом Мерлин присылает
		подсказку $z$ (зная эти биты).

		Первая строчка обозначает, что Мерлин довольно часто может убедить Артура, какие бы биты Артур не выбрал.
		Мерлину достаточно, чтобы был хотя бы один его ответ, который устроит Артура.
		Вторая строчка обозначает, что если слово в языке не лежит, то у Мерлина очень редко есть
		хоть какая-то стратегия, убеждающая Артура.
	\end{Def}

\subsection{Неравенства из тервера}
	Полезно знать: неравенства Маркова и Чебышёва (можно посмотреть в Википедии).

	Также полезно знать следующее неравенство (Чернова):
	пусть у нас есть монетка, которая выдаёт единицу с вероятностью $p$
	и ноль с вероятностью $1-p$.
	Пусть мы кинули её $n$ раз, получили последовательность $x_1, \dots, x_n$.
	Тогда есть такое неравенство (оно точно верно, но, может быть, в оригинальном неравенстве чуть
	точнее степень при $n$):
	\[
		Pr\left[\left|\frac{\sum x_i}{n} - p\right| > \epsilon\right] \le 2n^2e^{-2\epsilon^2n}
	\]
	Если мы кидаем независимые монетки, то вероятность уйти далеко от матожидания экспоненциально убывает.

\section{Разбор задач}
\problem{38}
	Разбирала Лиза Третьякова.

	Давайте алгоритм определит значение каждой переменной случайно, равновероятно, независимо.
	Он отработает за линейное время.
	Давайте теперь посчитаем матожидание числа выполненных клозов (пусть всего клозов $k$).
	Введём характеристическую функцию $z_j$ "--- она равна единице,
	если клоз $C_j$ выполнился, и нулю иначе.
	Матожидание числа выполненных клозов (по линейности матожидания) равно
	\[ E\left[\sum z_j\right] = \sum_{j=1}^k 1 \cdot Pr[z_j = 1] + 0 \cdot Pr[z_j = 0]\]
	Теперь оценим вероятность выполнения каждого отдельного клоза ($Pr[z_j=1]$).
	Каждый клоз может быть не выполнен только в $\sfrac 18$ случаев "--- когда все три входящие
	в него переменные имеют определённые значения, обнуляющие соответствующие вхождения.
	А выполнен, соответственно, в $\sfrac 78$ случаев.
	Значит, матожидание числа выполненных клозов "--- $\sfrac 78 \cdot k$

	\begin{Rem}
		Мы считаем, что все клозы имеют размер ровно три и в каждый клоз входят
		три \textit{различные} переменные, иначе последнее рассуждение про вероятность неверно.
	\end{Rem}

\problem{39}
	Разбирал Сева Степанов.

	У нас есть алгоритм, который умеет находить хорошее приближение (из предыдущей задачи).
	Давайте будем его запускать, пока не найдём набор, выполняющий хотя бы $\sfrac 78$ клозов.
	Такой набор всегда есть "--- это, во-первых, следует из матожидания числа выполненных клозов,
	а во-вторых мы это доказывали в первом семестре (через матожидание).
	Будем считать, что в формуле $n$ переменных и $m$ клозов.
	Ответ на задачу не больше $m$, а мы как раз найдём приближение не хуже $\sfrac 78$.

	Осталось лишь понять, почему это решение будет работать в среднем за полином.
	Давайте сначала посмотрим, какова доля наборов, выполняющих хотя бы $\sfrac 78$ клозов.

	Обозначим за $f(\vec X)$ долю клозов, выполненную в формуле набором $\vec X$:
	\[
		f(\vec X) \coloneq \frac{\sum_{k=1}^m z_k(\vec X)}{m}
	\]
	Рассмотрим отдельно наборы, выполняющие <<много>> клозов (хотя бы $\sfrac 78$) и остальные,
	выполняющие мало клозов:
	\begin{gather*}
		\begin{aligned}
			A &\coloneq \{ \vec X \mid f(\vec X) \ge \sfrac 7 8 \} \\
			B &\coloneq \{ \vec X \mid f(\vec X) < \sfrac 7 8 \}
		\end{aligned} \\
		|A|+|B| = 2^n \\
		\begin{aligned}
			c_1 &\coloneq \frac{|A|}{2^n} &
			x &\coloneq \frac{\sum_{\vec X \in A} f(\vec X)}{|A|} \\
			c_2 &\coloneq \frac{|B|}{2^n} &
			y &\coloneq \frac{\sum_{\vec X \in B} f(\vec X)}{|B|}
		\end{aligned}
	\end{gather*}
	Мы знаем, что матожидаение выполненной доли клозов в точности равно $\sfrac 78$, стало быть:
	\begin{gather*}
		xc_1 + yc_2 = \frac 78\\
		xc_1 + y(1 - c_1) = \frac 78\\
		xc_1 + y - yc_1 = \frac 78\\
		c_1(x-y) = \frac 78 - y\\
		c_1 = \frac{\sfrac 78 - y}{x-y} \ge \frac{\sfrac 78 - y}{1-y} = 1 - \frac{\sfrac18}{1-y}\\
	\end{gather*}
	Мы хотим оценить $c_1$ снизу, т.е. надо оценить вычитаемое сверху, т.е. его знаменатель $1-y$
	снизу, т.е. $y$ сверху.
	Для этого оценим $f(\vec X)$, если $\vec X \in B$:
	\begin{align*}
		f(\vec X) &< \frac 7 8 \\
		\frac{\sum_{k=1}^m z_k(\vec X)}{m} &< \frac 7 8 \\
		\sum_{k=1}^m z_k(\vec X) &< \frac {7m} 8 \\
		\sum_{k=1}^m z_k(\vec X) &\le \frac {7m} 8 - 1 \\
		f(\vec X) = \frac{\sum_{k=1}^m z_k(\vec X)}{m} &\le \frac 7 8 - \frac 1 m = \frac{7m-8}{8m} \\
	\end{align*}
	А раз $y$ есть среднее $f(\vec X)$, то можно оценить:
	\begin{gather*}
		\begin{aligned}
			y &\le \frac{7m-8}{8m} \\
			1 - y &\ge \frac{m+8}{8m} \\
		\end{aligned}
		\begin{aligned}
			c_1
				&\ge 1 - \frac{\sfrac 18}{1 - y}
				 \ge 1 - \frac 1 8 \cdot \frac{8m}{m+8} = \\
				&= 1 - \frac{m}{m+8}
				 = \frac{8}{m+8}
		\end{aligned}
	\end{gather*}	
	Таким образом, с вероятностью $\frac{1}{P(m)}$ (где $P(m)$ "--- некоторый полином,
	который можно оценить сверху как $n^k$ для некоторого $k$ и всех $n \ge 1$)
	мы угадаем правильную расстановку переменных с первого раза.

	Теперь оценим математическое ожидание $T(m)$ времени работы алгоритма до первого успеха.
	На первом шаге мы либо получили правильную расстановку, либо ничего не изменилось и мы запускаемся еще раз:
	\begin{align*}
		T(m) &= m + \left(1 - \frac{1}{P(m)}\right) T(m) \\
		T(m)P(m) &= mP(m) + (P(m)-1)T(m) \\
		T(m) &= mP(m) \\
	\end{align*}
	Получили, что время матожидание времени работы полиномиально от $m$.
	\begin{Rem}
		Альтернативно можно перебрать количество шагов, через которое мы получим ответ,
		вынести $m$ за скобку и просуммировать геометрическую прогрессию со знаменателем $1-\sfrac{1}{P(m)}$, получим то же самое.
	\end{Rem}
	\begin{assertion}
		На самом деле, мы нигде не пользовались тем, что на первом шаге мы работаем ровно $m$ "--- могли
		взять любой полином.
		То есть в общем случае получаем, что если у нас есть полиномиальный алгоритм, который
		выдаёт ответ с вероятностью хотя бы $\frac{1}{Poly(n)}$, то если мы будем его запускать,
		пока не получим ответ, то получим в среднем полиномиальный алгоритм.
	\end{assertion}

\problem{41}
\subsubsection{<<а>>}
	Разбирал Никита Подгузов.

    Докажаем сначала в одну сторону: у нас имеется полиномиальная по времени
    вероятностная машина $M$, которая с вероятностью $\ge 12$ выдаст правильный ответ, а не вопросик.
    Давайте будем её запускать, пока не получим не-вопросик, как в задаче 39.
    Посчитаем матожидание времени работы.
    Пусть машина $M$ работала за не более чем $P(n)$.
    На первой итерации мы запускаем $M$ и с вероятностью $\frac 12$ останавливаемся, а с вероятностью $\frac 12$ запускаемся заново.
    Суммарное время работы:
    \begin{align*}
    	T(n) = P(n) + \frac12 T(n) \\
    	2T(n) = 2P(n) + T(n) \\
    	T(n) = 2P(n)
	\end{align*}
	Получили полином.

	В другую сторону: пусть есть $L \in \ZPP$ и есть рандомизированное машина Тьюринга
	с полиномиальным матожиданием времени работы $E=P(n)$.
	Дадим ей поработать $2P(n)$ шагов, по неравенству Маркова получим, что с вероятностью не больше $\sfrac 12$
	она не закончит работать за время $2P(n)$, в таком случае выдаём вопросик.
	Иначе выдаём ответ машины.

\subsubsection{<<б>>}
	Разбирал Дима Лапшин.

	Покажем, что $\RP \cap \co\RP \subseteq \ZPP$.
	Пусть у нас есть задача, и для неё есть два алгоритма "--- один из класса $\RP$, другой из класса $\co\RP$.
	Давайте запустим их одновременно, пусть алгоритм из $\RP$ выдал $a_1$, а алгоритм из $\co\RP$ выдал $a_2$.
	Если $a_1=1$, то это точный ответ (в эту сторону $\RP$ не ошибается) сразу выдаём 1.
	Если $a_2=0$, то это точный ответ (в эту сторону $\co\RP$ не ошибается) сразу выдаём 0.
	А если ни то, ни другое, то оба алгоритма не уверены в своём ответе и надо выдасть вопросительный знак.
	Посчитаем вероятность того, что выдастся вопросительный знак:
	\begin{itemize}
		\item
			Если слово лежало в языке, то ошибся алгоритм из $\RP$, это происходит с вероятностью не больше $\frac 12$
			Алгоритм из $\co\RP$ не ошибся, но это неважно.
		\item
			Если слово не лежало в языке, то ошибся алгоритм из $\co\RP$, это происходит с вероятностью не больше $\frac 12$
			Алгоритм из $\RP$ не ошибся, но это неважно.
	\end{itemize}
	Значит, вопросительный знак будем выдавать с вероятностью не больше $\frac 1 2$.

	Теперь обратное включение.
	Есть язык $L$ и хотим проверить $x \stackrel{?}{\in} L$.
	Построим машины для $L$, лежащие в классах $\RP$ и $\co\RP$, первые действия будут одинаковые:
	\begin{enumerate}
		\item Запустим машину из пункта <<а>>, если она выдала ответ "--- его и вернём.
		\item Если она выдала вопросик "--- то выдадим тот ответ, в котором нам разрешено ошибаться:
			\begin{itemize}
				\item
					Если мы строим машину для $\RP$, выдаём нолик
				\item
					Если мы строим машину для $\co\RP$, выдаём единицу
			\end{itemize}
	\end{enumerate}
	Получаем, что любая задача из $ZPP$ лежит и в $RP$, и в $\co RP$, что и требовалось.

\problem{42}
	Разбирала Надя Бугакова.

	Давайте нарисуем граф: вершинам соответствуют конфигурация машины Тьюринга (конфигурацией
	считаем состояние машины плюс состояние рабочих лент).
	Конфигураций полиномиальное число, так как память лишь логарифмическая.
	Из каждой вершины ведёт либо одно ребро (если переходы из конфигурации не используют случайные биты),
	либо два ребра "--- одно в случае, если случайный бит равен нулю, другое "--- если единице.
	Заметим, что граф у нас по условию ацикличен, иначе есть какая-то случайная строка, на которой машина будет работать бесконечно.

	Значит, граф можно топологически отсортировать.
	А потом "--- динамическим программированием посчитать для каждой вершины количество случайных строк,
	по которым можно попасть в каждую вершину.
	Потом посмотрим, в какое из терминальных состояний "--- принимающее или отвергающее мы приходили чаще.

	Заметим, что это всё можно сделать по полиномиальное время.
	Конфигураций машины полином, граф получаем полиномиального размера, отсортировать можно за полином.
	Время работы машины не больше, чем полиномиальное, стало быть, количество
	различных случайных строк можно записать с использованием полиномиального числа бит.
	Значит, в каждой вершине будет записано число длины не более полинома.

	\begin{Rem}
		Это, вообще говоря, неправильное определение класса $\mathsf{BPL}$.
		В правильном определении у нас гарантируется лишь 
		то, что правильный ответ получаем с вероятностью больше $\sfrac 23$, больше ничего не известно
		(в частности, неизвестно, что машина всегда завершается).

		Но вроде всё равно лежит в $P$.
		Решается примерно так: мы сопоставляем каждой вершине переменную <<с какой вероятностью
		примем строку из этого состояние>>, составляем систему уравнений и решаем
		её методом Гаусса с некоторой точностью (оказывается, что её можно ограничить).

		\TODO разобраться с противоречием с Complexity Zoo (спросил по почте)
	\end{Rem}

\section{Подсказки}
\subsection{Задача 37}
	Что такое булева формула?
	Это какое-то дерево.
	Подсказка такая: давайте найдём вершину, поддерево которой имеет размер порядка половины всего дерева.
	Тогда если мы знаем в ней значение, то ответ на исходную формулу можно посчитать формулой половинного размера,
	просто заменив поддерево на константу.

\subsection{Задача 40}
	Надо понизить ошибку.
	Она нулём не станет, но класс $\NP$ нам позволяет проверять ответ.
	К сожалению, для этого нужна подсказка, и с ходу не очевидно, как она связана
	со случайными битами.
	Предлагают почитать первые лекции про классы $\NP$ и $\widetilde{\NP}$.
